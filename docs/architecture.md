# MCP Commit Story Architecture

## Overview

MCP Commit Story follows a **background generation architecture** with automatic journal creation triggered by git commits. This design prioritizes seamless workflow integration and user control over manual operations.

## Architecture Rationale

### Why Background Generation?

1. **Workflow Respect**: No interruption to development flow - journal entries are created silently after commits
2. **Fresh Context**: Each journal entry is generated by a fresh AI agent with comprehensive context, ensuring quality without dependency on persistent state
3. **User Control**: Developers control when and how context is added through manual reflection tools and context capture
4. **Reliability**: Direct git hook execution eliminates complex intermediate mechanisms and dependency chains
5. **Simplicity**: Clear, linear flow from commit → context collection → journal generation

### Core Architecture

```
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│   Git Commit    │    │ Standalone       │    │   Journal       │
│   (Trigger)     │───▶│ Generator        │───▶│   Entry         │
│                 │    │ (Background)     │    │   Created       │
└─────────────────┘    └──────────────────┘    └─────────────────┘
                              │
                              ▼
                       ┌──────────────────┐
                       │ Context Sources  │
                       │ • Git diff/log   │
                       │ • Chat history   │
                       │ • Recent journals││
                       └──────────────────┘
```

## Background Generation Flow

### 1. Git Hook Trigger
- **Post-commit hook** executes after each commit
- **Direct execution** of standalone journal generator
- **No intermediate files** or complex coordination required
- **Never blocks** git operations

### 2. Context Collection
- **Git Context**: Commit metadata, diffs, file changes (always available)
- **Chat History**: Two-stage intelligent filtering (commit-based time window + AI boundary detection)
- **Recent Journals**: Today's journal + 2 most recent daily entries for continuity
- **Project Context**: README (or configured overview file) ensures AI always understands project goals

### 3. Chat History Collection
- **Commit-based time windows**: Precise filtering based on git commit boundaries
- **Enhanced metadata**: Messages include timestamps and session names
- **Natural scoping**: Development conversations naturally bounded by commits
- **Rich context**: Complete conversation history with full fidelity
- **No artificial limiting**: Precise commit-based time windows eliminate need for message caps

### 4. Fresh AI Generation
- **Fresh AI instance** for each journal entry (no persistent context)
- **Comprehensive input**: All collected context provided to AI
- **Structured output**: Human-readable + machine-tagged journal entries
- **Quality focus**: Grounded in real data, captures emotion and decisions

### 5. Automatic Summaries
- **Daily summaries**: Generated automatically when date boundaries are detected
- **Future summaries**: Weekly, monthly, quarterly, yearly (planned)
- **Hierarchical context**: Daily summaries use journal entries, weekly summaries use daily summaries, etc.

## MCP Server Role

The MCP server provides **interactive tools only**:

### User-Controlled Operations
- **journal/add-reflection**: Add manual thoughts and reflections
- **journal/capture-context**: Capture AI knowledge for future journal context
- **journal/generate-summary**: "What did I do yesterday?" or "Help me report July's work to my boss"

### Setup Operations  
- **journal/init**: Initialize journal structure
- **journal/install-hook**: Install git hooks

**Key Point**: The MCP server is NOT required for core journal generation - it runs independently in the background.

## AI Context Capture System

*Added: Complete system specification for AI context capture functionality*

The AI context capture mechanism solves the "lost context between AI sessions" problem by preserving valuable insights from AI conversations directly into the journal workflow.

**Problem Statement:**
AI-assisted development generates valuable insights about architecture, implementation patterns, and technical decisions. Without a preservation mechanism, this knowledge disappears when the AI conversation ends, forcing developers to rediscover solutions and losing important contextual understanding.

**Solution Architecture:**
```
AI Conversation → Manual Capture → Daily Journal → Context Collection → Enhanced Future Journals
      ↓              ↓                 ↓               ↓                     ↓
   [Insight]    [MCP Tool]        [File Storage]   [Auto-Parsing]     [Informed AI]
```

**Implementation Components:**

1. **Capture Interface**: MCP tool (`journal/capture-context`) for manual insight preservation
2. **Storage Integration**: Automatic append to daily journal files with consistent formatting  
3. **Context Collection**: Parsing and retrieval of captured insights during journal generation
4. **AI Enhancement**: Inclusion of preserved context in AI prompts for richer journal entries

**Capture Format:**
```markdown
____

### 2:30 PM — AI Context Capture

[Preserved insight content - implementation details, architectural decisions, debugging discoveries, etc.]
```

**Integration Workflow:**

1. **During Development**: Developer discovers valuable insight through AI conversation
2. **Manual Capture**: Uses MCP tool to preserve insight in today's journal 
3. **Automatic Storage**: Insight appended to daily journal file with proper formatting
4. **Context Building**: Future journal generation includes captured insights as context
5. **Enhanced Journals**: AI generates more informed entries that reference previous learnings
6. **Knowledge Persistence**: Critical insights survive across development sessions

This system transforms ephemeral AI conversation insights into permanent knowledge assets that accumulate over time, creating a rich context base that enhances all future development documentation.

[Link to AI Context Capture Guide](ai-context-capture-guide.md) for complete usage instructions.

## 4-Layer Standalone Journal Generator Architecture

The journal generation process follows a **4-layer architecture** that separates concerns between data collection, orchestration, section generation, and AI invocation:

### Layer 1: Context Collection (Programmatic + AI Filtering)
- **Responsibility**: Gather raw data with intelligent chat filtering
- **Key Functions**:
  - `collect_git_context(commit_hash)` - Git metadata, diffs, and commit info
  - `collect_chat_history()` - Two-stage chat filtering (time window + AI boundary detection)
  - `collect_journal_context()` - Existing journal entries, reflections, and manual context

These functions handle data extraction and intelligent filtering. The chat history collection includes AI-powered filtering as a sub-step to ensure only commit-relevant conversations are included.

### Layer 2: Orchestration (Coordination)
- **Module**: `standalone_generator.py`
- **Responsibility**: Coordinate the entire journal generation flow
- **Key Functions**:
  - `generate_journal_entry_standalone()` - Main orchestration function
  - Calls all context collectors to gather raw data
  - Builds the `JournalContext` structure with collected data (conversation history comes pre-structured)
  - Determines which generators need AI vs programmatic execution
  - Assembles complete journal entry from generated sections
  - Handles errors gracefully - if one section fails, others continue

### Layer 3: Section Generators (Mixed AI and Programmatic)
- **Responsibility**: Generate specific journal entry sections
- **Mixed Execution Model**:

**Programmatic Generators** (no AI required):
- `generate_commit_metadata_section()` - Pure git data extraction
- `generate_technical_synopsis_section()` - Code change analysis
- `generate_file_changes_section()` - Git diff analysis

**AI-Powered Generators** (require AI interpretation):
- `generate_summary_section()` - Narrative summary of changes
- `generate_accomplishments_section()` - Achievement interpretation
- `generate_frustrations_section()` - Challenge identification
- `generate_tone_mood_section()` - Emotional indicator detection
- `generate_discussion_notes_section()` - Key conversation excerpts
- `generate_decision_points_section()` - Decision moment identification

Each AI generator has a docstring prompt and returns a placeholder for AI execution.

### Layer 4: AI Invocation (Infrastructure)
- **Responsibility**: Execute AI-powered components with graceful degradation
- **Single AI Invocation Point**:

**Section Generation** (Layer 3):
- `execute_ai_function(func, context)` - Executes AI-powered generators
- Reads docstring prompts and formats context
- Sends to AI provider and parses responses
- Provides graceful degradation (returns empty sections if AI unavailable)

**Direct Integration**: Chat history comes pre-structured and chronologically ordered directly from the chat history system.



## Complete Data Flow

```
1. Git hook triggers → process_git_hook()
2. Orchestrator called → generate_journal_entry_standalone()
3. Context collectors gather → git data, chronological chat history, journal content
4. Build JournalContext with conversation history
5. For each generator:
   - Programmatic ones: execute directly
   - **AI Calls**: AI generators via executor
6. Assembly → sections combined into complete journal entry
7. Save → journal entry written to daily file
```

The system provides complete chronologically-ordered chat history with timestamps and session names directly from the chat history system.

### Standalone Journal Generator (Layer 2 Implementation)
```python
def generate_journal_entry_standalone(commit_hash: Optional[str] = None, hook_type: str = 'post-commit') -> bool:
    """Main orchestration function using 4-layer architecture"""
    try:
        # Layer 1: Collect all raw context
        git_context = collect_git_context(commit_hash)
        conversation_history = collect_chat_history()  # Chronological conversations from chat history
        journal_context = collect_journal_context()
        
        # Build the complete journal context
        context = JournalContext(
            git_context=git_context,
            conversation_history=conversation_history,
            journal_context=journal_context,
            hook_type=hook_type
        )
        
        # Layer 3: Generate all sections using mixed execution
        journal_sections = {}
        
        # Execute programmatic generators directly
        for section_name, generator_func in PROGRAMMATIC_GENERATORS.items():
            try:
                journal_sections[section_name] = generator_func(context)
            except Exception as e:
                log_error(f"Failed to generate {section_name} section: {str(e)}")
                journal_sections[section_name] = {}
        
        # Execute AI generators via Layer 4 (AI invocation infrastructure)
        for section_name, generator_func in AI_GENERATORS.items():
            try:
                if is_ai_available():
                    journal_sections[section_name] = execute_ai_function(generator_func, context)  # AI Calls
                else:
                    log_info(f"AI unavailable, skipping {section_name} section")
                    journal_sections[section_name] = {}
            except Exception as e:
                log_error(f"Failed to generate {section_name} section: {str(e)}")
                journal_sections[section_name] = {}
        
        # Save the complete journal entry
        save_journal_entry(journal_sections)
        return True
        
    except Exception as e:
        log_error(f"Journal generation failed: {str(e)}")
        return False
```

### Generator Registry (Layer 3 Implementation)
```python
# Define which generators are AI-powered vs programmatic
PROGRAMMATIC_GENERATORS = {
    'metadata': generate_commit_metadata_section,
    'technical_synopsis': generate_technical_synopsis_section,
    'file_changes': generate_file_changes_section,
}

AI_GENERATORS = {
    'summary': generate_summary_section,
    'accomplishments': generate_accomplishments_section,
    'frustrations': generate_frustrations_section,
    'tone_mood': generate_tone_mood_section,
    'discussion_notes': generate_discussion_notes_section,
    'decision_points': generate_decision_points_section,
}
```

## Chat System Integration

> **For User-Friendly Overview**: See the [Chat Integration User Guide](chat-integration-guide.md) for a complete explanation of how chat integration works from a user perspective.

The system integrates with chat history systems to provide rich conversational context for journal entries:

### Chat Integration Features
- **Complete archive**: Access to comprehensive conversation history
- **Chronological order**: Messages already sorted with accurate timestamps
- **Rich context**: Session names, file attachments, and conversation threading
- **Workspace isolation**: Automatic filtering to project-specific conversations
- **Git correlation**: Precise commit-based time windows (previous commit timestamp to current commit timestamp)

### Implementation
```python
# Chat collection using chat history system
conversation = collect_chat_history(commit_timestamp)  # Pre-structured, chronological
```

### Chat Collection Time Window Strategy

The chat integration uses a precise commit-based time window approach for collecting relevant chat conversations:

**Time Window Definition**:
- **Initial window**: Previous commit timestamp to current commit timestamp
- **AI refinement**: A separate AI agent analyzes the conversation within this window to identify the exact point where work on the current commit began
- **Final scope**: Only messages from the AI-identified boundary point onwards are included

**Why This Approach**:
- **Exact correlation**: Captures the exact development conversation that led to the commit
- **No arbitrary windows**: Eliminates guesswork about what constitutes "relevant" timeframes
- **Direct relationship**: Chat context directly correlates with the work done
- **Natural boundaries**: Handles varying development session lengths naturally (some commits take minutes, others take hours or days)

**Implementation**:
```python
def collect_chat_history_for_commit(commit_hash: str) -> List[ChatMessage]:
    # Get current commit timestamp
    current_timestamp = get_commit_timestamp(commit_hash)
    
    # Get previous commit timestamp  
    previous_commit = get_previous_commit(commit_hash)
    previous_timestamp = get_commit_timestamp(previous_commit)
    
    # Filter conversations within this window
    return filter_conversations_by_timeframe(
        start_time=previous_timestamp,
        end_time=current_timestamp
    )
```

This approach ensures journal entries contain exactly the conversations that contributed to each commit, providing precise context without noise from unrelated development sessions.

### AI Boundary Detection

After the initial commit-based time window filtering, a dedicated AI agent performs intelligent boundary detection:

- **Separate AI instance**: Fresh context for objective analysis
- **Boundary identification**: Finds the exact message where current commit work begins
- **Conservative filtering**: Removes only messages definitively unrelated to the commit
- **Fallback behavior**: If AI filtering fails, uses all messages in the time window

This two-stage approach (time window + AI filtering) ensures journal entries contain precisely the conversations that led to each commit, with no extraneous context from previous work.

## Benefits of This Architecture

### For Developers
- **Zero Friction**: Commit and forget - journal entries appear automatically
- **No Workflow Disruption**: Background generation never interrupts work
- **Full Control**: Add context when needed, ignore when focused
- **Rich Context**: Every entry has comprehensive, relevant information
- **Decision Capture**: Decision points section captures architectural and design choices

### For Quality
- **Fresh Perspective**: Each entry generated by fresh AI instance with full context
- **Grounded Content**: All entries based on real git changes and conversations  
- **Complete Conversation History**: Rich conversational context from comprehensive chat data
- **Chronological Accuracy**: Pre-structured conversations with timestamps and session context
- **Precise Context**: AI boundary detection ensures only relevant conversations are included
- **Mixed Execution**: Programmatic sections provide reliable data, AI sections add interpretation
- **Consistent Format**: Standardized structure across all entries

### For Reliability
- **Simplified Concerns**: Clear separation between data collection, orchestration, section generation, and AI invocation
- **Reduced AI Dependencies**: Fewer failure points with direct data access
- **Graceful Degradation**: System works even when AI unavailable (programmatic sections continue)
- **Error Isolation**: If one section fails, others continue processing
- **No Dependencies**: Core functionality works without MCP server
- **Fast Execution**: Optimized with programmatic processing and pre-structured data

### For Maintainability
- **Separation of Concerns**: Each layer has a single, well-defined responsibility
- **Testable Components**: Layers can be tested independently with appropriate mocks
- **Extensible Design**: Generators can be added to either programmatic or AI categories
- **Clear Data Flow**: Linear progression through layers with explicit boundaries

## User Experience Patterns

### Automatic Operation (Primary)
```bash
# Developer works normally
git add .
git commit -m "Implement user authentication"
# → Journal entry automatically created in background
# → Daily summary generated if date boundary crossed
```

### Manual Context Addition (When Needed)
```bash
# Via MCP tools in editor/AI assistant
journal/add-reflection "Learned about JWT security considerations"
journal/generate-summary  # "What did I do yesterday?" or "Help me report July's work to my boss"
```

### Summary Generation
```bash
# Automatic daily summaries when date changes
```

## Future Architecture Considerations

### Planned Enhancements
- **Multi-timeframe summaries**: Weekly, monthly, quarterly, yearly
- **Pattern recognition**: Identify recurring themes and challenges
- **Content suggestions**: Recommend blog post topics from journal patterns
- **Integration hooks**: Export to external systems (blogs, documentation)

### Scalability
- **Repository isolation**: Each repo maintains independent journal
- **Context optimization**: Intelligent pruning of large chat histories
- **Performance monitoring**: Telemetry for background generation timing
- **Resource management**: Configurable limits for AI processing

## Related Documentation

- **[MCP API Specification](mcp-api-specification.md)** - Interactive tool reference
- **[Implementation Guide](implementation-guide.md)** - Technical implementation details
- **[Journal Behavior](journal-behavior.md)** - Content generation rules
- **[Context Collection](context-collection.md)** - Data gathering system
- **[Testing Standards](testing_standards.md)** - Quality assurance