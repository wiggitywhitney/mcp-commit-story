# Task ID: 71
# Title: Implement Lightweight Tagging and Narrative Threading for Journal Summaries
# Status: pending
# Dependencies: none
# Priority: medium
# Description: Enhance journal summaries to automatically surface recurring themes, story arcs, and patterns from journal entries to support conference talk preparation and retrospectives.
# Details:
## Goals
- Help surface story arcs that span multiple journal entries
- Identify recurring themes and patterns in development work
- Connect emotional reactions to technical decisions over time
- Support conference talk preparation by highlighting narrative threads
- Enable retrospectives that show cause-and-effect patterns

## Design Principles
- Lightweight and flexible approach
- Should emerge organically from journal content
- Design decisions to be made during implementation based on real usage patterns
- Focus on helping the user discover their own themes rather than imposing predefined categories

## Implementation Approach
- Start with simple theme detection and evolve based on actual usage
- Allow user to guide what themes are important rather than hardcoding specific tags
- Build incrementally with user feedback
- Design for extensibility and customization

# Test Strategy:
## Test Strategy

### 1. Unit Tests for Tagging System

```python
def test_add_tags_to_journal_content():
    """Test that appropriate tags are added to journal content"""
    # Test breakthrough detection
    breakthrough_content = "Today I finally solved the persistent caching issue that was blocking progress."
    tagged_content = add_tags_to_journal_content(breakthrough_content, {})
    assert "#breakthrough" in tagged_content
    
    # Test AI misstep detection
    ai_misstep_content = "The AI model gave incorrect suggestions for optimizing the database queries."
    tagged_content = add_tags_to_journal_content(ai_misstep_content, {})
    assert "#AI-misstep" in tagged_content
    
    # Test pivot detection
    pivot_content = "We decided to change our approach to authentication after reviewing security concerns."
    tagged_content = add_tags_to_journal_content(pivot_content, {})
    assert "#pivot" in tagged_content
    
    # Test recurring issue detection
    recurring_content = "We're still facing the same memory leak issue in the processing module."
    tagged_content = add_tags_to_journal_content(recurring_content, {})
    assert "#recurring-issue" in tagged_content
    
    # Test multiple tag detection
    complex_content = "After the AI gave incorrect suggestions again, we pivoted to a manual approach."
    tagged_content = add_tags_to_journal_content(complex_content, {})
    assert "#AI-misstep" in tagged_content
    assert "#pivot" in tagged_content
    assert "#recurring-issue" in tagged_content
```

### 2. Unit Tests for Emotion-Tech Pairing

```python
def test_enhance_journal_prompt_with_emotion_tech_pairing():
    """Test that emotion-tech pairing is correctly added to prompts"""
    original_prompt = "# Journal Entry\n\nWrite about today's work.\n\n# Additional Instructions:\nBe concise."
    enhanced_prompt = enhance_journal_prompt_with_emotion_tech_pairing(original_prompt)
    
    # Check that the emotion-tech guidance was added
    assert "emotional reaction" in enhanced_prompt
    assert "intuitions guided" in enhanced_prompt
    assert "feelings about the code" in enhanced_prompt
    
    # Check that original content is preserved
    assert "# Journal Entry" in enhanced_prompt
    assert "Write about today's work" in enhanced_prompt
    assert "Be concise" in enhanced_prompt
```

### 3. Unit Tests for AI-as-Character Implementation

```python
def test_implement_ai_as_character():
    """Test that AI-as-character guidance is correctly added to prompts"""
    original_prompt = "# Journal Entry\n\nWrite about today's work.\n\n# Additional Instructions:\nBe concise."
    enhanced_prompt = implement_ai_as_character(original_prompt)
    
    # Check that the AI-as-character guidance was added
    assert "AI tools and assistants as characters" in enhanced_prompt
    assert "consistent personality" in enhanced_prompt
    assert "conversations with a teammate" in enhanced_prompt
    
    # Check that original content is preserved
    assert "# Journal Entry" in enhanced_prompt
    assert "Write about today's work" in enhanced_prompt
    assert "Be concise" in enhanced_prompt
```

### 4. Unit Tests for Recurring Theme Detection

```python
def test_detect_recurring_themes():
    """Test that recurring themes are correctly detected"""
    # Create mock journal entries
    from datetime import datetime, timedelta
    
    class MockEntry:
        def __init__(self, date, content):
            self.date = date
            self.content = content
    
    today = datetime.now()
    entries = [
        MockEntry(today - timedelta(days=5), "Working on the API. #breakthrough"),
        MockEntry(today - timedelta(days=4), "The AI gave incorrect suggestions. #AI-misstep"),
        MockEntry(today - timedelta(days=3), "Still having issues with the API. #recurring-issue"),
        MockEntry(today - timedelta(days=2), "The AI hallucinated again. #AI-misstep"),
        MockEntry(today - timedelta(days=1), "Changed our approach to the API. #pivot")
    ]
    
    themes = detect_recurring_themes(entries)
    
    # Check that AI-misstep is detected as recurring (appears twice)
    assert 'AI-misstep' in themes['counts']
    assert themes['counts']['AI-misstep'] == 2
    
    # Check that examples are provided
    assert 'examples' in themes
    assert 'AI-misstep' in themes['examples']
    assert len(themes['examples']['AI-misstep']) == 2
```

### 5. Unit Tests for Narrative Summary Generation

```python
def test_generate_narrative_summary():
    """Test that narrative summaries correctly connect events"""
    # Create mock journal entries and themes
    from datetime import datetime, timedelta
    
    class MockEntry:
        def __init__(self, date, content):
            self.date = date
            self.content = content
    
    today = datetime.now()
    entries = [
        MockEntry(today - timedelta(days=5), "Working on the API. #breakthrough"),
        MockEntry(today - timedelta(days=4), "The AI gave incorrect suggestions. #AI-misstep"),
        MockEntry(today - timedelta(days=3), "Still having issues with the API. #recurring-issue"),
        MockEntry(today - timedelta(days=2), "The AI hallucinated again. #AI-misstep"),
        MockEntry(today - timedelta(days=1), "Changed our approach to the API. #pivot")
    ]
    
    recurring_themes = {
        'counts': {
            'AI-misstep': 2,
            'recurring-issue': 1,
            'breakthrough': 1,
            'pivot': 1
        },
        'examples': {
            'AI-misstep': [
                {'date': today - timedelta(days=4), 'excerpt': "The AI gave incorrect suggestions."},
                {'date': today - timedelta(days=2), 'excerpt': "The AI hallucinated again."}
            ]
        }
    }
    
    summary = generate_narrative_summary(entries, recurring_themes)
    
    # Check that the summary includes all expected sections
    assert "Development Journey Overview" in summary
    assert "AI-misstep Narrative" in summary
    assert "Cause and Effect Patterns" in summary
    
    # Check that the summary connects events chronologically
    assert "first instance" in summary
    assert today.strftime("%b") in summary  # Month abbreviation should be in the summary
```

### 6. Integration Tests for Enhanced Summary Generation

```python
def test_enhanced_summary_generation():
    """Test that the enhanced summary generator correctly integrates with existing code"""
    # Mock the original summary generator
    def mock_original_generator(*args, **kwargs):
        return "# Original Summary\n\nThis is the original summary content."
    
    # Create the enhanced generator
    enhanced_generator = enhance_summary_generation(mock_original_generator)
    
    # Create mock journal entries
    from datetime import datetime, timedelta
    
    class MockEntry:
        def __init__(self, date, content, metadata=None):
            self.date = date
            self.content = content
            self.metadata = metadata or {}
    
    today = datetime.now()
    entries = [
        MockEntry(today - timedelta(days=5), "Working on the API. #breakthrough"),
        MockEntry(today - timedelta(days=4), "The AI gave incorrect suggestions. #AI-misstep"),
        MockEntry(today - timedelta(days=3), "Still having issues with the API. #recurring-issue"),
        MockEntry(today - timedelta(days=2), "The AI hallucinated again. #AI-misstep"),
        MockEntry(today - timedelta(days=1), "Changed our approach to the API. #pivot")
    ]
    
    # Generate enhanced summary
    enhanced_summary = enhanced_generator(journal_entries=entries, date=today)
    
    # Check that the enhanced summary contains both original and narrative content
    assert "Original Summary" in enhanced_summary
    assert "Narrative Summary" in enhanced_summary
    assert "Development Journey Overview" in enhanced_summary
```

### 7. End-to-End Tests

```python
def test_end_to_end_tagging_and_narrative_threading():
    """Test the complete tagging and narrative threading workflow"""
    # This test should:
    # 1. Generate journal entries with tags
    # 2. Extract tags to metadata
    # 3. Generate a summary with narrative threading
    # 4. Verify the summary contains the expected narrative elements
    
    # Set up test repository and configuration
    test_repo = setup_test_repository()
    test_config = load_test_configuration()
    
    # Generate journal entries with tags
    for i in range(5):
        generate_test_journal_entry(test_repo, test_config, i)
    
    # Generate summary
    summary = generate_summary(test_repo, test_config)
    
    # Verify summary contains narrative elements
    assert "Development Journey Overview" in summary
    assert "Cause and Effect Patterns" in summary
    
    # Verify tags were correctly applied and used
    assert re.search(r'#\w+(?:-\w+)*', summary)
```

### 8. Configuration Tests

```python
def test_tagging_configuration():
    """Test that tagging configuration options work correctly"""
    # Test with tagging disabled
    config = {"tagging": {"enabled": False}}
    content = "Today I finally solved the persistent caching issue."
    tagged_content = add_tags_to_journal_content(content, {}, config)
    assert "#breakthrough" not in tagged_content
    
    # Test with custom tags
    config = {
        "tagging": {
            "enabled": True,
            "custom_tags": [
                {"pattern": r"refactor", "tag": "#code-cleanup"}
            ]
        }
    }
    content = "Spent the day refactoring the authentication module."
    tagged_content = add_tags_to_journal_content(content, {}, config)
    assert "#code-cleanup" in tagged_content
    
    # Test metadata-only storage
    config = {
        "tagging": {
            "enabled": True,
            "store_in_content": False,
            "store_as_metadata": True
        }
    }
    content = "Today I finally solved the persistent caching issue."
    entry = MockEntry(datetime.now(), content)
    tagged_entry = process_journal_entry_tags(entry, config)
    assert "#breakthrough" not in tagged_entry.content
    assert "breakthrough" in tagged_entry.metadata.get("tags", [])
```
