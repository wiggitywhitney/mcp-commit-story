# Task ID: 45
# Title: Design and Implement SQLite Workspace Detection and Reader
# Status: pending
# Dependencies: None
# Priority: medium
# Description: Create a robust SQLite reader function that uses Python's built-in sqlite3 module to access Cursor's chat database with cross-platform workspace detection capabilities.
# Details:
This task implements a foundational SQLite reader function for accessing Cursor's chat database across multiple platforms, with a strong focus on workspace detection:

1. **Core Database Access Layer**:
```python
@trace_mcp_operation
def get_cursor_chat_database(user_override_path=None):
    """
    Locate and connect to the Cursor chat SQLite database
    
    Args:
        user_override_path: Optional user-provided path to database
        
    Returns:
        sqlite3.Connection: Database connection object
        
    Raises:
        CursorDatabaseNotFoundError: If database cannot be located
        CursorDatabaseAccessError: If database exists but cannot be accessed
    """
    # Try user override path first if provided
    if user_override_path:
        if os.path.exists(user_override_path):
            try:
                return sqlite3.connect(user_override_path)
            except sqlite3.Error as e:
                raise CursorDatabaseAccessError(f"Cannot access user-provided database: {e}")
        else:
            # Don't fail immediately, try standard locations
            pass
    
    # Platform detection
    platform_name = platform.system().lower()
    
    # Multi-platform workspace detection
    base_paths = []
    
    if platform_name == "windows":
        base_paths.append(os.path.join(os.environ.get("APPDATA", ""), "Cursor", "User", "workspaceStorage"))
    elif platform_name == "darwin":  # macOS
        base_paths.append(os.path.expanduser("~/Library/Application Support/Cursor/User/workspaceStorage"))
    elif platform_name == "linux":
        # Check if running in WSL
        if os.path.exists("/proc/version") and "microsoft" in open("/proc/version").read().lower():
            username = os.environ.get("USER", "")
            base_paths.append(f"/mnt/c/Users/{username}/AppData/Roaming/Cursor/User/workspaceStorage")
        
        # Standard Linux paths
        base_paths.append(os.path.expanduser("~/.config/Cursor/User/workspaceStorage"))
        base_paths.append(os.path.expanduser("~/.cursor-server/data/User/workspaceStorage"))
    
    # Workspace hash discovery
    for base_path in base_paths:
        if not os.path.exists(base_path):
            continue
            
        # Find workspace hash directories
        workspace_dirs = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]
        
        for workspace_dir in workspace_dirs:
            # Look for cursor-chat-browser pattern
            db_path = os.path.join(base_path, workspace_dir, "cursor-chat-browser", "chat.db")
            if os.path.exists(db_path):
                try:
                    return sqlite3.connect(db_path)
                except sqlite3.Error as e:
                    # Log but continue trying other paths
                    logging.warning(f"Found but couldn't access database at {db_path}: {e}")
    
    # If we get here, we couldn't find or access the database
    raise CursorDatabaseNotFoundError("Could not locate Cursor chat database in any standard location")

@trace_mcp_operation
@functools.lru_cache(maxsize=32)
def query_cursor_chat_database(sql, params=None, user_override_path=None):
    """
    Execute a query against the Cursor chat database with caching
    
    Args:
        sql: SQL query to execute
        params: Parameters for the query
        user_override_path: Optional user-provided path to database
        
    Returns:
        list: Query results
        
    Raises:
        CursorDatabaseError: If query fails
    """
    try:
        conn = get_cursor_chat_database(user_override_path)
        cursor = conn.cursor()
        
        if params:
            cursor.execute(sql, params)
        else:
            cursor.execute(sql)
            
        results = cursor.fetchall()
        cursor.close()
        conn.close()
        return results
    except (CursorDatabaseNotFoundError, CursorDatabaseAccessError) as e:
        # Re-raise these specific errors
        raise
    except Exception as e:
        raise CursorDatabaseError(f"Error executing query: {e}")
```

2. **Custom Exception Classes**:
```python
class CursorDatabaseError(Exception):
    """Base exception for Cursor database errors"""
    pass

class CursorDatabaseNotFoundError(CursorDatabaseError):
    """Exception raised when Cursor database cannot be found"""
    pass
    
class CursorDatabaseAccessError(CursorDatabaseError):
    """Exception raised when Cursor database exists but cannot be accessed"""
    pass
```

3. **Configuration Integration**:
```python
@trace_mcp_operation
def get_cursor_database_config():
    """Get cursor database configuration from user settings"""
    config = get_mcp_config()
    return config.get("cursor_database", {})
```

4. **Schema Validation Function**:
```python
@trace_mcp_operation
def validate_cursor_chat_schema(conn):
    """
    Validate that the connected database has the expected schema
    
    Args:
        conn: SQLite connection
        
    Returns:
        bool: True if schema is valid
        
    Raises:
        CursorDatabaseSchemaError: If schema validation fails
    """
    required_tables = ["conversations", "messages"]
    cursor = conn.cursor()
    
    # Get list of tables
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
    tables = [row[0] for row in cursor.fetchall()]
    
    # Check required tables exist
    for table in required_tables:
        if table not in tables:
            raise CursorDatabaseSchemaError(f"Required table '{table}' not found in database")
    
    return True
```

5. **Implementation Notes**:
- The function uses Python's built-in sqlite3 module without external dependencies
- Implements multi-method workspace detection based on platform-specific paths
- Includes proper error handling with custom exception classes
- Uses lru_cache for performance optimization
- Maintains compatibility with the existing system (does not remove old collect_ai_chat_context function)
- Includes telemetry via @trace_mcp_operation decorators

# Test Strategy:
The implementation should be verified through the following test strategy:

1. **Unit Tests**:
```python
def test_platform_detection():
    """Test that the correct platform is detected"""
    # Mock platform.system() to return different values
    with patch('platform.system', return_value='Windows'):
        assert is_windows() == True
        assert is_macos() == False
        assert is_linux() == False
    
    with patch('platform.system', return_value='Darwin'):
        assert is_windows() == False
        assert is_macos() == True
        assert is_linux() == False
        
    with patch('platform.system', return_value='Linux'):
        assert is_windows() == False
        assert is_macos() == False
        assert is_linux() == True

def test_database_path_resolution():
    """Test that database paths are correctly resolved for each platform"""
    # Test Windows path resolution
    with patch('platform.system', return_value='Windows'), \
         patch('os.environ.get', return_value='C:\\Users\\Test\\AppData\\Roaming'), \
         patch('os.path.exists', return_value=True), \
         patch('os.listdir', return_value=['hash1']), \
         patch('os.path.isdir', return_value=True):
        
        paths = get_potential_database_paths()
        assert 'C:\\Users\\Test\\AppData\\Roaming\\Cursor\\User\\workspaceStorage\\hash1\\cursor-chat-browser\\chat.db' in paths

    # Similar tests for macOS and Linux...

def test_database_connection():
    """Test database connection with mock database"""
    # Create a temporary SQLite database
    conn = sqlite3.connect(':memory:')
    cursor = conn.cursor()
    
    # Create test schema
    cursor.execute('CREATE TABLE conversations (id TEXT, title TEXT)')
    cursor.execute('CREATE TABLE messages (id TEXT, conversation_id TEXT, content TEXT)')
    
    # Insert test data
    cursor.execute('INSERT INTO conversations VALUES (?, ?)', ('conv1', 'Test Conversation'))
    cursor.execute('INSERT INTO messages VALUES (?, ?, ?)', ('msg1', 'conv1', 'Test message'))
    
    conn.commit()
    
    # Mock the database connection function
    with patch('your_module.get_cursor_chat_database', return_value=conn):
        # Test query function
        results = query_cursor_chat_database('SELECT * FROM conversations')
        assert len(results) == 1
        assert results[0][0] == 'conv1'
        
        results = query_cursor_chat_database('SELECT * FROM messages WHERE conversation_id = ?', ('conv1',))
        assert len(results) == 1
        assert results[0][2] == 'Test message'

def test_error_handling():
    """Test error handling for various failure scenarios"""
    # Test database not found
    with patch('your_module.get_cursor_chat_database', side_effect=CursorDatabaseNotFoundError("Test error")):
        with pytest.raises(CursorDatabaseNotFoundError):
            query_cursor_chat_database('SELECT 1')
    
    # Test database access error
    with patch('your_module.get_cursor_chat_database', side_effect=CursorDatabaseAccessError("Test error")):
        with pytest.raises(CursorDatabaseAccessError):
            query_cursor_chat_database('SELECT 1')
    
    # Test query error
    with patch('your_module.get_cursor_chat_database', return_value=sqlite3.connect(':memory:')):
        with pytest.raises(CursorDatabaseError):
            query_cursor_chat_database('SELECT * FROM nonexistent_table')
```

2. **Integration Tests**:
```python
def test_telemetry_integration():
    """Test that telemetry is correctly captured"""
    collector = TelemetryCollector()
    
    with collector:
        try:
            # This should trigger telemetry
            get_cursor_chat_database()
        except:
            pass
    
    # Verify telemetry was captured
    operations = collector.get_operations()
    assert any(op.name == 'get_cursor_chat_database' for op in operations)

def test_cross_platform_compatibility():
    """Test cross-platform compatibility with different path formats"""
    # This would be a manual test on different platforms
    # Document the test procedure for each platform
    pass
```

3. **Manual Testing Checklist**:
   - Test on Windows with standard installation
   - Test on macOS with standard installation
   - Test on Linux with standard installation
   - Test on WSL2 with Windows Cursor installation
   - Test with user override path
   - Test with missing database
   - Test with corrupted database
   - Test with unexpected schema
   - Verify error messages are clear and actionable

4. **Performance Testing**:
   - Verify caching works by measuring repeated query times
   - Test with large database to ensure performance is acceptable

5. **Documentation Verification**:
   - Ensure all functions have proper docstrings
   - Verify error messages are clear and provide troubleshooting guidance
   - Check that telemetry is properly documented

# Subtasks:
## 1. Implement Platform-specific Path Detection Module [done]
### Dependencies: None
### Description: Create a module that detects SQLite workspace paths across different operating systems (Windows, macOS, Linux, WSL).
### Details:
Develop functions to identify default SQLite database locations on each platform. Include environment variable support for custom paths. Implement path validation to verify existence and accessibility. Create a unified interface that abstracts platform differences. Handle edge cases like network drives and non-standard installations.
<info added on 2025-06-21T08:05:52.470Z>
# Implementation Plan for Subtask 45.1: Platform-specific Path Detection Module

## Objective
Create a module that detects SQLite workspace paths across different operating systems (Windows, macOS, Linux, WSL)

### TDD Steps:
1. **WRITE TESTS FIRST**
   - Create `tests/unit/test_platform_detection.py`
   - Test `get_cursor_workspace_paths()` function across platforms
   - Test cases: Windows (APPDATA), macOS (Library), Linux (~/.config), WSL (/mnt/c/Users)
   - Test `detect_platform()` function returns correct OS
   - Test `validate_workspace_path(path)` function for existence/accessibility
   - Test environment variable expansion and user home detection
   - **RUN TESTS - VERIFY THEY FAIL**

2. **GET APPROVAL FOR DESIGN CHOICES**
   - **PAUSE FOR MANUAL APPROVAL**: Module location (`src/mcp_commit_story/cursor_db/platform.py` vs `src/mcp_commit_story/platform_utils.py`)
   - **PAUSE FOR MANUAL APPROVAL**: WSL detection strategy (check /proc/version vs environment variables)
   - **PAUSE FOR MANUAL APPROVAL**: Path priority order when multiple potential locations exist

3. **IMPLEMENT FUNCTIONALITY**
   - Create `src/mcp_commit_story/cursor_db/platform.py`
   - Implement `detect_platform()` using platform.system()
   - Implement `get_cursor_workspace_paths()` with platform-specific logic
   - Add WSL detection via /proc/version parsing
   - Handle environment variable expansion safely
   - **RUN TESTS - VERIFY THEY PASS**

4. **DOCUMENT AND COMPLETE**
   - Add documentation IF NEEDED in three places:
     1. **Docs directory**: Add cursor-database-setup.md with platform-specific setup instructions
     2. **PRD**: Update system requirements section for supported platforms
     3. **Engineering Spec**: Add platform detection architecture details and make sure TOC is current
   - **Run the entire test suite and make sure all tests are passing**
   - **Make sure pyproject.toml is updated as needed**
   - **MARK COMPLETE**
</info added on 2025-06-21T08:05:52.470Z>
<info added on 2025-06-21T08:23:46.974Z>
**IMPLEMENTATION COMPLETED** ✅

**What was implemented:**
- Created `src/mcp_commit_story/cursor_db/` package with `__init__.py` and `platform.py`
- Implemented comprehensive cross-platform path detection with approved design choices:
  - Module location: `src/mcp_commit_story/cursor_db/platform.py` (new cursor_db package)
  - WSL detection: `/proc/version` file with environment variable fallback
  - Path priority: Environment variable → Platform defaults → Fallbacks

**Key functionality delivered:**
- `detect_platform()` - Auto-detects Windows, macOS, Linux, WSL
- `get_cursor_workspace_paths()` - Returns prioritized list of potential paths
- `validate_workspace_path()` - Validates path existence and accessibility
- `find_valid_workspace_paths()` - Returns only existing/accessible paths
- `get_primary_workspace_path()` - Returns first valid path or None

**Platform-specific implementations:**
- **Windows**: APPDATA and USERPROFILE environment variables with path normalization
- **macOS**: `~/Library/Application Support/Cursor/User/workspaceStorage`
- **Linux**: XDG_CONFIG_HOME with fallback to `~/.config`
- **WSL**: Searches `/mnt/c/Users/*/AppData/Roaming` + Linux paths

**Testing achievements:**
- **23 comprehensive unit tests** covering all platforms and edge cases
- **All tests passing** including mocking for cross-platform scenarios
- **Test coverage**: Platform detection, path validation, environment variables, edge cases

**Technical highlights:**
- Robust error handling with custom `CursorPathError` exception
- Cross-platform path normalization (Windows `\` → `/`)
- Environment variable support (`CURSOR_WORKSPACE_PATH`)
- Fallback paths for portable installations
- Comprehensive logging for debugging

**Ready for integration** with database connection functions (subtask 45.2)
</info added on 2025-06-21T08:23:46.974Z>

## 2. Develop Core Database Connection and Query Functions [pending]
### Dependencies: 45.1
### Description: Build the core functionality for establishing connections to SQLite databases and executing queries with proper resource management.
### Details:
Implement connection pooling for performance optimization. Create parameterized query functions to prevent SQL injection. Add transaction support for atomic operations. Implement result caching mechanisms to improve performance. Develop connection timeout and retry logic for robustness.
<info added on 2025-06-21T08:06:17.165Z>
# Implementation Plan for Subtask 45.2: Core Database Connection and Query Functions

## Objective
Build the core functionality for establishing connections to SQLite databases and executing queries with proper resource management

### TDD Steps:
1. **WRITE TESTS FIRST**
   - Create `tests/unit/test_database_connection.py`
   - Test `get_cursor_chat_database(user_override_path=None)` function
   - Test cases: successful connection, database not found, permission denied, corrupted database
   - Test `query_cursor_chat_database(sql, params=None)` function
   - Test parameterized queries and SQL injection prevention
   - Test connection resource cleanup and caching behavior
   - **RUN TESTS - VERIFY THEY FAIL**

2. **GET APPROVAL FOR DESIGN CHOICES**
   - **PAUSE FOR MANUAL APPROVAL**: Caching strategy (LRU cache vs connection pooling vs no caching)
   - **PAUSE FOR MANUAL APPROVAL**: Database file discovery algorithm (first found vs best match vs user choice)
   - **PAUSE FOR MANUAL APPROVAL**: Resource management approach (context managers vs explicit cleanup)

3. **IMPLEMENT FUNCTIONALITY**
   - Create `src/mcp_commit_story/cursor_db/connection.py`
   - Implement `get_cursor_chat_database()` with platform detection integration
   - Add `@functools.lru_cache` for connection optimization
   - Implement `query_cursor_chat_database()` with parameterized query support
   - Add proper SQLite connection resource cleanup
   - **RUN TESTS - VERIFY THEY PASS**

4. **DOCUMENT AND COMPLETE**
   - Add documentation IF NEEDED in three places:
     1. **Docs directory**: Update cursor-database-setup.md with connection troubleshooting
     2. **PRD**: Update database requirements and performance characteristics
     3. **Engineering Spec**: Add database connection architecture and make sure TOC is current
   - **Run the entire test suite and make sure all tests are passing**
   - **Make sure pyproject.toml is updated as needed**
   - **MARK COMPLETE**
</info added on 2025-06-21T08:06:17.165Z>

## 3. Create Error Handling and Custom Exceptions [pending]
### Dependencies: 45.2
### Description: Design and implement a comprehensive error handling system with custom exceptions for different failure scenarios.
### Details:
Define a hierarchy of custom exception classes for different error types (connection, query, schema, etc.). Implement detailed error messages with context information. Add logging integration for error tracking. Create recovery mechanisms for non-fatal errors. Implement graceful degradation for partial system failures.
<info added on 2025-06-21T08:06:36.402Z>
# Implementation Plan for Subtask 45.3: Error Handling and Custom Exceptions

## Objective
Design and implement a comprehensive error handling system with custom exceptions for different failure scenarios

### TDD Steps:
1. **WRITE TESTS FIRST**
   - Create `tests/unit/test_cursor_db_exceptions.py`
   - Test custom exception hierarchy: `CursorDatabaseError`, `CursorDatabaseNotFoundError`, `CursorDatabaseAccessError`, `CursorDatabaseSchemaError`
   - Test exception raising in connection and query functions
   - Test error message clarity and context information
   - Test graceful degradation when database is unavailable
   - **RUN TESTS - VERIFY THEY FAIL**

2. **GET APPROVAL FOR DESIGN CHOICES**
   - **PAUSE FOR MANUAL APPROVAL**: Exception hierarchy structure (inheritance vs composition)
   - **PAUSE FOR MANUAL APPROVAL**: Error message format and detail level for user troubleshooting
   - **PAUSE FOR MANUAL APPROVAL**: Logging integration strategy (log all errors vs only unexpected ones)

3. **IMPLEMENT FUNCTIONALITY**
   - Create `src/mcp_commit_story/cursor_db/exceptions.py`
   - Define custom exception classes with clear inheritance hierarchy
   - Add context-rich error messages with troubleshooting hints
   - Integrate with existing telemetry system using `@trace_mcp_operation`
   - Update connection/query functions to raise appropriate exceptions
   - **RUN TESTS - VERIFY THEY PASS**

4. **DOCUMENT AND COMPLETE**
   - Add documentation IF NEEDED in three places:
     1. **Docs directory**: Add troubleshooting section to cursor-database-setup.md
     2. **PRD**: Update error handling section for user experience
     3. **Engineering Spec**: Add exception handling architecture and make sure TOC is current
   - **Run the entire test suite and make sure all tests are passing**
   - **Make sure pyproject.toml is updated as needed**
   - **MARK COMPLETE**
</info added on 2025-06-21T08:06:36.402Z>

## 4. Implement Schema Validation and Integrity Checks [pending]
### Dependencies: 45.2, 45.3
### Description: Develop functionality to validate database schemas and perform integrity checks on SQLite workspaces.
### Details:
Create schema definition and validation utilities. Implement version detection for database compatibility. Add integrity check functions to verify database health. Develop migration helpers for schema updates. Create reporting tools for schema validation results.
<info added on 2025-06-21T08:06:58.158Z>
# Implementation Plan for Subtask 45.4: Schema Validation and Integrity Checks

## Objective
Develop functionality to validate database schemas and perform integrity checks on SQLite workspaces

### TDD Steps:
1. **WRITE TESTS FIRST**
   - Create `tests/unit/test_schema_validation.py`
   - Test `validate_cursor_chat_schema(conn)` function
   - Test cases: valid schema, missing tables, unexpected schema, empty database
   - Test `get_schema_version(conn)` and version compatibility checks
   - Test `check_database_integrity(conn)` for corruption detection
   - Mock SQLite connection objects for isolated testing
   - **RUN TESTS - VERIFY THEY FAIL**

2. **GET APPROVAL FOR DESIGN CHOICES**
   - **PAUSE FOR MANUAL APPROVAL**: Required table names and schema structure expectations
   - **PAUSE FOR MANUAL APPROVAL**: Schema validation strictness level (strict vs permissive)
   - **PAUSE FOR MANUAL APPROVAL**: Database version compatibility strategy (support older versions vs require latest)

3. **IMPLEMENT FUNCTIONALITY**
   - Create `src/mcp_commit_story/cursor_db/validation.py`
   - Implement `validate_cursor_chat_schema()` with expected table checks
   - Add schema version detection and compatibility validation
   - Implement basic integrity checks using SQLite PRAGMA commands
   - Integrate with custom exception system for clear error reporting
   - **RUN TESTS - VERIFY THEY PASS**

4. **DOCUMENT AND COMPLETE**
   - Add documentation IF NEEDED in three places:
     1. **Docs directory**: Add schema requirements section to cursor-database-setup.md
     2. **PRD**: Update database compatibility requirements
     3. **Engineering Spec**: Add schema validation details and make sure TOC is current
   - **Run the entire test suite and make sure all tests are passing**
   - **Make sure pyproject.toml is updated as needed**
   - **MARK COMPLETE**
</info added on 2025-06-21T08:06:58.158Z>

## 5. Build Testing Framework Implementation [pending]
### Dependencies: 45.1, 45.2, 45.3, 45.4
### Description: Create a comprehensive testing framework for the SQLite workspace detection and reader functionality.
### Details:
Develop unit tests for each component. Create integration tests for cross-component functionality. Implement platform-specific test suites. Add performance benchmarking tests. Create mock objects for testing without actual database dependencies. Implement continuous integration setup for automated testing.
<info added on 2025-06-21T08:07:17.093Z>
# Implementation Plan for Subtask 45.5: Testing Framework Implementation

## Objective
Create a comprehensive testing framework for the SQLite workspace detection and reader functionality

### TDD Steps:
1. **WRITE TESTS FIRST**
   - Create `tests/integration/test_cursor_db_integration.py`
   - Test full end-to-end workflow: platform detection → database discovery → connection → query
   - Test cross-platform mock scenarios for all supported OS types
   - Test performance with large mock databases and caching behavior
   - Test telemetry integration with all database operations
   - **RUN TESTS - VERIFY THEY FAIL**

2. **IMPLEMENT FUNCTIONALITY**
   - Create comprehensive integration test suite
   - Add mock database fixtures for testing without real Cursor installation
   - Implement performance benchmarking utilities
   - Add telemetry verification helpers
   - Create cross-platform test scenarios using parameterized tests
   - **RUN TESTS - VERIFY THEY PASS**

3. **DOCUMENT AND COMPLETE**
   - Add documentation IF NEEDED in three places:
     1. **Docs directory**: Add testing guide to cursor-database-setup.md
     2. **PRD**: Update testing and quality assurance section
     3. **Engineering Spec**: Add testing framework architecture and make sure TOC is current
   - **Run the entire test suite and make sure all tests are passing**
   - **Make sure pyproject.toml is updated as needed**
   - **MARK COMPLETE**
</info added on 2025-06-21T08:07:17.093Z>

## 6. Add Telemetry Instrumentation to Platform Detection [pending]
### Dependencies: 45.1, 45.2, 45.3, 45.4, 45.5
### Description: Integrate telemetry instrumentation throughout the platform detection module to track performance, errors, and usage patterns.
### Details:
Add comprehensive telemetry instrumentation to the platform detection module following the telemetry standards documented in docs/telemetry.md:\n\n1. **Function-level instrumentation:**\n   - Add `@trace_mcp_operation` decorators to public functions\n   - Add performance timing for path detection operations\n   - Track platform detection accuracy and frequency\n\n2. **Error categorization:**\n   - Instrument custom exceptions with telemetry context\n   - Track error rates by platform type\n   - Monitor permission and access failures\n\n3. **Performance metrics:**\n   - Monitor workspace enumeration duration\n   - Track memory usage for large directory scans\n   - Measure cache hit/miss rates\n\n4. **Usage analytics:**\n   - Track which platforms are most commonly detected\n   - Monitor path validation success rates\n   - Record workspace discovery patterns\n\n5. **Integration testing:**\n   - Verify telemetry data is properly collected\n   - Test telemetry performance impact\n   - Validate telemetry configuration options"

