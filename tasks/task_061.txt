# Task ID: 61
# Title: Implement Composer Integration for Full Chat History Access
# Status: in-progress
# Dependencies: None
# Priority: high
# Description: Upgrade cursor_db to use Composer instead of aiService, providing access to complete chronologically-ordered conversation history with timestamps and session names, filtered by git commit time windows.
# Details:
This task involves replacing the current aiService implementation with Cursor's Composer system to improve chat history access:

## Required Reading Before Implementation

**READ FIRST**: `/Users/wiggitywhitney/Repos/mcp-commit-story/docs/cursor-chat-discovery.md` - explains Composer database structure
**REFERENCE**: `/Users/wiggitywhitney/Repos/mcp-commit-story/cursor_chat_sample.json` - shows real data examples

## Key Technical Details from Research

- Composer uses a two-database system:
  - Workspace database (session metadata) in `workspaceStorage/{hash}/state.vscdb`
  - Global database (actual messages) in `globalStorage/state.vscdb`
- Session metadata key: `composer.composerData` in workspace ItemTable
- Message headers key: `composerData:{composerId}` in global cursorDiskKV table
- Individual messages key: `bubbleId:{composerId}:{bubbleId}` in global cursorDiskKV table
- Messages are already chronologically ordered with timestamps

## Implementation Steps

1. Create a new module that interfaces with Composer databases:
   ```typescript
   // Example implementation
   import { Database } from 'better-sqlite3';
   import * as path from 'path';
   import { execSync } from 'child_process';
   
   export class ComposerChatProvider {
     private workspaceDb: Database;
     private globalDb: Database;
     
     constructor(gitRepoPath: string) {
       // Auto-detect workspace based on git repository path
       const workspaceHash = this.detectWorkspaceHash(gitRepoPath);
       this.workspaceDb = new Database(path.join('workspaceStorage', workspaceHash, 'state.vscdb'));
       this.globalDb = new Database(path.join('globalStorage', 'state.vscdb'));
     }
     
     async getChatHistoryForCommit(commitHash: string): Promise<ChatMessage[]> {
       // Get current commit timestamp
       const currentCommitTimestamp = this.getCommitTimestamp(commitHash);
       
       // Get previous commit timestamp
       const previousCommitHash = this.getPreviousCommitHash(commitHash);
       const previousCommitTimestamp = this.getCommitTimestamp(previousCommitHash);
       
       // Define time window: from previous commit to current commit
       const startTime = previousCommitTimestamp;
       const endTime = currentCommitTimestamp;
       
       // Get session metadata from workspace DB
       const sessions = this.getSessionMetadata();
       
       // Get messages from global DB filtered by time window
       const messages = this.getMessagesInTimeWindow(sessions, startTime, endTime);
       
       return messages;
     }
     
     private getCommitTimestamp(commitHash: string): number {
       const timestamp = execSync(
         `git show -s --format=%ct ${commitHash}`,
         { encoding: 'utf-8' }
       ).trim();
       
       // Convert to milliseconds (git returns seconds)
       return parseInt(timestamp) * 1000;
     }
     
     private getPreviousCommitHash(commitHash: string): string {
       return execSync(
         `git rev-parse ${commitHash}~1`,
         { encoding: 'utf-8' }
       ).trim();
     }
     
     private getSessionMetadata() {
       const result = this.workspaceDb.prepare(
         "SELECT value FROM ItemTable WHERE key = 'composer.composerData'"
       ).get();
       
       return JSON.parse(result.value);
     }
     
     private getMessagesInTimeWindow(sessions, startTime, endTime) {
       const messages = [];
       
       for (const session of sessions) {
         // Get message headers
         const headerKey = `composerData:${session.composerId}`;
         const headerRow = this.globalDb.prepare(
           "SELECT value FROM cursorDiskKV WHERE key = ?"
         ).get(headerKey);
         
         if (!headerRow) continue;
         
         const header = JSON.parse(headerRow.value);
         
         // Get individual messages
         for (const bubbleId of header.bubbleIds) {
           const messageKey = `bubbleId:${session.composerId}:${bubbleId}`;
           const messageRow = this.globalDb.prepare(
             "SELECT value FROM cursorDiskKV WHERE key = ?"
           ).get(messageKey);
           
           if (!messageRow) continue;
           
           const message = JSON.parse(messageRow.value);
           
           // Filter by timestamp
           if (message.timestamp >= startTime && message.timestamp <= endTime) {
             messages.push({
               id: message.id,
               role: message.role,
               content: message.content,
               timestamp: message.timestamp,
               sessionName: session.name || 'Unnamed Session',
               // Add other required fields
             });
           }
         }
       }
       
       // Sort by timestamp to ensure chronological order
       return messages.sort((a, b) => a.timestamp - b.timestamp);
     }
     
     private detectWorkspaceHash(gitRepoPath: string): string {
       // Implementation to detect workspace hash based on git repository path
       // This would involve examining the workspaceStorage directory
       // and matching with the current repository
     }
   }
   ```

2. Update the cursor_db module to use the new Composer integration:
   - Replace existing aiService calls with Composer calls
   - Update data models to include timestamps and session names
   - Remove any code related to AI-based conversation reconstruction
   - Implement clear error handling if Composer databases not found

3. Update the API to maintain backward compatibility while providing new features:
   - Keep the same function signatures but enhance return data
   - Add timestamp filtering based on git commit time
   - Include session names in the returned data

4. Update tests:
   - Create new mock data based on the Composer database structure
   - Update existing tests to expect the new data format
   - Add tests for time window filtering

## Implementation Decisions (APPROVED)

- **Time Window Strategy**: Use git commit timestamps to define chat window (previous commit to current commit)
- **Message Filtering**: Filter conversations that happened during the development of the current commit
- **Data Richness**: Include session names from Composer (e.g., "Implement authentication")
- **Workspace Detection**: Auto-detect based on current git repository path
- **Error Handling**: Fail clearly if Composer not found (no fallback to aiService)

# Test Strategy:
1. Unit Tests:
   - Create unit tests for the new Composer integration module
   - Test edge cases like empty chats, very large chats, and malformed responses
   - Mock Composer database responses for predictable testing
   - Test commit-based time window filtering logic with various commit pairs
   - Verify workspace detection logic with different repository paths

2. Integration Tests:
   - Test the integration between cursor_db and the Composer system
   - Verify that chat history is correctly retrieved and formatted
   - Test with real Composer databases in a staging environment
   - Verify session names are correctly included in the output

3. Regression Tests:
   - Ensure all features that previously used aiService continue to work
   - Verify that chat history access works for both recent and older conversations
   - Check that the full chronological history is correctly maintained
   - Verify commit-based time window filtering works correctly with real git commits

4. Performance Tests:
   - Measure and compare load times for chat history between old and new implementations
   - Test with large chat histories to ensure performance remains acceptable
   - Verify memory usage doesn't increase significantly
   - Test performance of SQLite queries on large Composer databases

5. Manual Testing:
   - Manually verify that the complete chat history is accessible
   - Check that the chronological ordering is correct
   - Verify that the UI correctly displays the expanded chat history
   - Test with real git commits to ensure commit-based time windows capture relevant conversations

6. Validation Criteria:
   - All chat history (not just 48 hours) is accessible
   - Messages are correctly filtered by commit-based time windows
   - Session names are included in the output
   - No regression in existing functionality
   - Performance meets or exceeds previous implementation
   - All automated tests pass
   - Journal entries show richer context from complete conversations

# Subtasks:
## 1. Study Composer Database Structure [done]
### Dependencies: None
### Description: Research phase reading docs/cursor-chat-discovery.md and cursor_chat_sample.json, create documentation
### Details:
**READ FIRST**: docs/cursor-chat-discovery.md - explains Composer database structure
**REFERENCE**: cursor_chat_sample.json - shows real data examples

Research the two-database system:
- Workspace database (session metadata) in workspaceStorage/{hash}/state.vscdb
- Global database (actual messages) in globalStorage/state.vscdb
- Session metadata key: composer.composerData in workspace ItemTable
- Message headers key: composerData:{composerId} in global cursorDiskKV table
- Individual messages key: bubbleId:{composerId}:{bubbleId} in global cursorDiskKV table

Create comprehensive documentation of findings for implementation phase.

## 2. Workspace Detection Function [done]
### Dependencies: None
### Description: TDD approach with approval checkpoints for workspace matching strategy
### Details:
**REFERENCE**: docs/cursor-chat-discovery.md for workspace detection strategies

1. Write failing tests for workspace detection based on git repository path
2. Run tests to confirm failure
3. PAUSE FOR MANUAL APPROVAL: Workspace matching strategy (exact path vs fuzzy matching)
4. Implement workspace hash detection function
5. Run tests to confirm they pass
6. Document the chosen approach

Function should auto-detect correct workspace database based on current git repository path by examining workspaceStorage directory structure.
<info added on 2025-06-29T20:47:45.606Z>
**APPROVED DESIGN DECISIONS** (Manual Approval Step 3 Complete)

Design Choice: **Fuzzy Matching with Fallback Strategy**

**Primary Approach**: Scan all workspace directories in workspaceStorage and check workspace.json files for matches

**Matching Criteria (Priority Order)**:
1. **Git remote URL match** (strongest signal - survives repo moves)
2. **Folder path match** (handles case where repo hasn't moved)  
3. **Project/folder name similarity** (last resort before fallback)

**Fallback**: Most recently modified workspace if no good match found
**No caching**: Keep stateless like rest of project
**Confidence threshold**: 0.8 for matches to avoid false positives

**Implementation Considerations**:
- Auto-detect correct workspace database based on current git repository
- Handle edge cases gracefully (missing workspace.json, corrupted data, etc.)
- Log warnings when using fallback strategies

**Telemetry Requirements**:
- Use @trace_mcp_operation decorator on main function
- Track detection_strategy: "workspace_json_match" | "most_recent" | "not_found"
- Track candidates_found: number of potential workspaces scanned
- Track match_confidence: 0.0-1.0 for workspace matches
- Track match_type: "git_remote" | "folder_path" | "folder_name" when matched
- Track fallback_used: boolean
- Error categorization: error.category: "workspace_detection"
- Add metrics: Counter for strategy usage, Histogram for detection duration
- Include span attributes: repo_path, selected workspace path, etc.

**Goal**: Robust solution that reliably finds right workspace database even when developers move/rename projects, with full observability.
</info added on 2025-06-29T20:47:45.606Z>

## 3. Commit-Based Time Window Filtering [pending]
### Dependencies: 61.1
### Description: Implement git timestamp filtering with approval for edge cases
### Details:
1. Write failing tests for time window filtering logic
2. Run tests to confirm failure
3. Implement git commit timestamp retrieval functions:
   - getCommitTimestamp(commitHash): Get timestamp for specific commit
   - getPreviousCommitHash(commitHash): Get previous commit hash
   - Handle git command execution errors
   - Convert git timestamps (seconds) to JavaScript timestamps (milliseconds)
4. PAUSE FOR MANUAL APPROVAL: Edge case handling (first commit, merge commits, detached HEAD)
5. Implement message filtering logic for time windows
6. Run tests to confirm they pass

Time window: previous commit timestamp to current commit timestamp.

## 4. ComposerChatProvider Class [pending]
### Dependencies: 61.1, 61.2, 61.3
### Description: Main interface class with approval for connection/caching strategies
### Details:
**REFERENCE**: docs/cursor-chat-discovery.md for database connection patterns

1. Write failing tests for ComposerChatProvider class
2. Run tests to confirm failure  
3. Create basic class structure with constructor and main methods
4. PAUSE FOR MANUAL APPROVAL: Database connection strategy (singleton vs per-request, connection pooling)
5. PAUSE FOR MANUAL APPROVAL: Caching strategy for session metadata and messages
6. Implement database connections to both workspace and global databases
7. Implement getChatHistoryForCommit method
8. Implement session metadata retrieval
9. Implement message retrieval with time filtering
10. Run tests to confirm they pass

Class should handle both workspace database (session metadata) and global database (actual messages).

## 5. Update query_cursor_chat_database Function [pending]
### Dependencies: 61.4
### Description: Replace aiService with Composer integration
### Details:
**REFERENCE**: src/mcp_commit_story/cursor_db/ module for current implementation

1. Write failing tests for updated query_cursor_chat_database function
2. Run tests to confirm failure
3. Replace aiService calls with ComposerChatProvider calls
4. Update function signature and return data to include timestamps and session names
5. Maintain backward compatibility for existing callers
6. Update error handling to handle Composer database failures
7. Run tests to confirm they pass
8. Document API changes

Function should maintain same external interface while providing richer data from Composer.

## 6. Remove Conversation Reconstruction Code [pending]
### Dependencies: 61.5
### Description: Eliminate AI-based reconstruction since Composer provides chronological data
### Details:
1. Identify all AI-based conversation reconstruction code in cursor_db module
2. Create tests to ensure removal doesn't break functionality
3. Remove message_reconstruction.py functions that are no longer needed
4. Remove any AI provider calls used for conversation ordering
5. Clean up imports and dependencies
6. Update documentation to reflect removal
7. Run all tests to ensure no regressions

Since Composer provides chronologically ordered messages with timestamps, AI-based reconstruction is redundant.

## 7. Update Data Models [pending]
### Dependencies: 61.5
### Description: Enhance with timestamps and session names
### Details:
**REFERENCE**: src/mcp_commit_story/context_types.py for current data models

1. Write failing tests for enhanced data models
2. Run tests to confirm failure
3. Update ChatMessage and related types to include:
   - timestamp: number (JavaScript timestamp in milliseconds)
   - sessionName: string (e.g., \"Implement authentication\")
   - composerId: string (for debugging/tracing)
   - bubbleId: string (for debugging/tracing)
4. Update any interfaces or type definitions
5. Ensure backward compatibility for existing code
6. Run tests to confirm they pass
7. Update documentation for new fields

Enhanced models should support the richer data available from Composer.

## 8. Comprehensive Error Handling [pending]
### Dependencies: 61.4, 61.5
### Description: Implement robust error handling for database access, git operations, and edge cases
### Details:
1. Write failing tests for various error scenarios
2. Run tests to confirm failure
3. Implement error handling for:
   - Composer databases not found or inaccessible
   - Corrupted database files
   - Git command failures (invalid commit hash, git not available)
   - Missing workspace detection
   - Network/permission issues
   - Invalid session data or missing bubbleIds
   - Database query failures
4. Add clear error messages with debugging information
5. Implement graceful degradation (fallback behaviors where appropriate)
6. Add logging for debugging purposes
7. Run tests to confirm proper error handling
8. Document error conditions and recovery strategies

Error handling should be comprehensive but never block system operation unnecessarily.

## 9. Mock Data for Testing [pending]
### Dependencies: 61.1, 61.7
### Description: Create comprehensive test fixtures based on real Composer database structure
### Details:
1. Analyze real Composer database structure from cursor_chat_sample.json
2. Create mock workspace database data:
   - Session metadata with composerIds
   - Workspace configuration data
   - Various session states (active, completed, etc.)
3. Create mock global database data:
   - Message headers with bubbleIds arrays
   - Individual bubble messages with timestamps
   - Various message types (user, assistant, system)
   - Multiple sessions with overlapping timeframes
4. Create edge case mock data:
   - Empty sessions
   - Corrupted data scenarios
   - Large message volumes
   - Missing references
5. Implement SQLite test database creation helpers
6. Document mock data structure and usage

Mock data should cover normal operations, edge cases, and error scenarios for comprehensive testing.

## 10. Basic Integration Testing [pending]
### Dependencies: 61.8, 61.9
### Description: Smoke tests and end-to-end validation
### Details:
1. Create smoke tests for basic functionality:
   - ComposerChatProvider can connect to databases
   - Workspace detection works with real repositories
   - Message retrieval returns expected format
   - Time window filtering produces reasonable results
2. Create end-to-end integration tests:
   - Full chat history retrieval workflow
   - Integration with existing MCP tools
   - Performance benchmarks vs previous implementation
   - Memory usage validation
3. Test with real Composer databases (if available)
4. Validate session names are correctly retrieved
5. Verify chronological ordering is maintained
6. Test commit-based time window accuracy
7. Run performance comparison tests
8. Document test results and any issues found

Tests should validate the complete integration works as expected in real-world scenarios.

## 11. Telemetry Integration [pending]
### Dependencies: 61.4, 61.5, 61.8
### Description: Add comprehensive telemetry coverage following project standards
### Details:
**REFERENCE**: docs/telemetry.md for project telemetry standards

1. Add @trace_mcp_operation decorators to all new functions:
   - ComposerChatProvider methods
   - Workspace detection functions
   - Time window filtering functions
   - Database query operations
2. Implement comprehensive metrics:
   - mcp_composer_operations_total{operation_type, status}
   - mcp_composer_database_query_duration_seconds{database_type}
   - mcp_workspace_detection_duration_seconds{detection_method}
   - mcp_time_window_filtering_duration_seconds
   - mcp_chat_message_count{session_name}
3. Add structured logging with trace correlation:
   - Database connection events
   - Workspace detection results
   - Time window calculations
   - Message filtering operations
   - Error conditions
4. Ensure graceful degradation (telemetry failures don't block operation)
5. Add telemetry validation tests
6. Document new metrics and traces
7. Verify integration with existing telemetry exporters

All telemetry should follow project standards: automatic trace correlation, JSON logging, and multi-exporter support.

