# Task ID: 46
# Title: Implement Direct Database Query Function
# Status: in-progress
# Dependencies: None
# Priority: medium
# Description: Create a function to query the Cursor chat database and extract complete conversation history with proper parsing and error handling, based on validated research findings.
# Details:
This task implements a robust database query function that extracts comprehensive chat data from Cursor's SQLite database, following the validated research findings in `docs/cursor-chat-database-research.md`:

1. **Core Query Function Implementation**:
```python
@trace_mcp_operation
def query_cursor_chat_database(workspace_path=None):
    """
    Query the Cursor chat database to extract complete conversation history.
    
    Args:
        workspace_path: Optional path to workspace. If None, uses detected workspace.
        
    Returns:
        List of conversation objects with structured message history
        
    Raises:
        CursorDatabaseError: When database access or parsing fails
    """
    try:
        # Get database path using the SQLite Reader function
        db_path = get_cursor_database_path(workspace_path)
        
        # Connect to database
        connection = sqlite3.connect(db_path)
        cursor = connection.cursor()
        
        # Query the confirmed active keys based on research findings
        user_prompts = _query_table_by_key(cursor, "ItemTable", "aiService.prompts")
        ai_responses = _query_table_by_key(cursor, "ItemTable", "aiService.generations")
        metadata = _query_table_by_key(cursor, "ItemTable", "composer.composerData")
        
        # Process the data into conversations
        conversations = _process_cursor_chat_data(user_prompts, ai_responses, metadata)
        
        # Check for potential truncation (100-message limit)
        if len(ai_responses) >= 100:
            logger.warning("Detected 100 AI responses - data may be truncated due to Cursor's message limit")
            conversations[0]["truncation_warning"] = True
        
        connection.close()
        return conversations
        
    except Exception as e:
        logger.error(f"Error querying Cursor chat database: {str(e)}")
        raise CursorDatabaseError(f"Failed to query chat database: {str(e)}")
```

2. **Helper Functions for Database Access**:
```python
@trace_mcp_operation
def _query_table_by_key(cursor, table_name, key_value):
    """Query a specific table by key value and return results."""
    try:
        cursor.execute(f"SELECT key, value FROM {table_name} WHERE key = ?", (key_value,))
        results = cursor.fetchall()
        return results
    except sqlite3.Error as e:
        logger.warning(f"Error querying {table_name} with key {key_value}: {str(e)}")
        return []
```

3. **Data Processing Function**:
```python
@trace_mcp_operation
def _process_cursor_chat_data(user_prompts, ai_responses, metadata):
    """Process the raw database data into structured conversations."""
    # Parse the raw data
    parsed_prompts = []
    for _, value in user_prompts:
        try:
            prompt_data = json.loads(value)
            if isinstance(prompt_data, list):
                for item in prompt_data:
                    if item.get("commandType") == 4:  # User prompt
                        parsed_prompts.append({
                            "text": item.get("text", ""),
                            "timestamp": item.get("unixMs", 0)
                        })
            elif prompt_data.get("commandType") == 4:  # Single user prompt
                parsed_prompts.append({
                    "text": prompt_data.get("text", ""),
                    "timestamp": prompt_data.get("unixMs", 0)
                })
        except json.JSONDecodeError:
            logger.warning("Failed to parse user prompt data")
    
    parsed_responses = []
    for _, value in ai_responses:
        try:
            response_data = json.loads(value)
            if isinstance(response_data, list):
                for item in response_data:
                    if item.get("type") == "composer":
                        parsed_responses.append({
                            "text": item.get("textDescription", ""),
                            "timestamp": item.get("unixMs", 0),
                            "uuid": item.get("generationUUID", str(uuid.uuid4()))
                        })
            elif response_data.get("type") == "composer":
                parsed_responses.append({
                    "text": response_data.get("textDescription", ""),
                    "timestamp": response_data.get("unixMs", 0),
                    "uuid": response_data.get("generationUUID", str(uuid.uuid4()))
                })
        except json.JSONDecodeError:
            logger.warning("Failed to parse AI response data")
    
    # Sort all messages by timestamp
    all_messages = []
    for prompt in parsed_prompts:
        all_messages.append({
            "role": "user",
            "content": prompt["text"],
            "timestamp": prompt["timestamp"],
            "id": str(uuid.uuid4())
        })
    
    for response in parsed_responses:
        all_messages.append({
            "role": "assistant",
            "content": response["text"],
            "timestamp": response["timestamp"],
            "id": response["uuid"]
        })
    
    # Sort by timestamp
    all_messages.sort(key=lambda x: x["timestamp"])
    
    # Assign parent_id based on message sequence
    for i in range(1, len(all_messages)):
        all_messages[i]["parent_id"] = all_messages[i-1]["id"]
    
    # Extract workspace metadata if available
    workspace_title = "Cursor Workspace"
    if metadata:
        try:
            metadata_json = json.loads(metadata[0][1])
            workspace_title = metadata_json.get("workspaceName", workspace_title)
        except (json.JSONDecodeError, IndexError):
            logger.warning("Failed to parse workspace metadata")
    
    # Create a single conversation object
    conversation = {
        "id": str(uuid.uuid4()),
        "title": workspace_title,
        "messages": all_messages,
        "truncation_warning": False  # Will be set to True if 100-message limit detected
    }
    
    return [conversation]
```

4. **Error Handling and Custom Exceptions**:
```python
class CursorDatabaseError(Exception):
    """Exception raised for errors in the Cursor database operations."""
    pass
```

5. **Caching Implementation**:
```python
@lru_cache(maxsize=32)
@trace_mcp_operation
def get_cached_conversations(workspace_path=None):
    """
    Cached version of query_cursor_chat_database to improve performance
    for repeated calls.
    """
    return query_cursor_chat_database(workspace_path)
```

6. **Telemetry Integration**:
```python
@trace_mcp_operation
def query_cursor_chat_database_with_telemetry(workspace_path=None):
    """Wrapper with telemetry for the database query function."""
    start_time = time.time()
    try:
        result = query_cursor_chat_database(workspace_path)
        telemetry.record_event(
            "cursor_db_query_success",
            {
                "duration_ms": (time.time() - start_time) * 1000,
                "conversation_count": len(result),
                "message_count": sum(len(conv["messages"]) for conv in result),
                "truncation_warning": any(conv.get("truncation_warning", False) for conv in result)
            }
        )
        return result
    except Exception as e:
        telemetry.record_event(
            "cursor_db_query_failure",
            {
                "duration_ms": (time.time() - start_time) * 1000,
                "error_type": type(e).__name__,
                "error_message": str(e)
            }
        )
        raise
```

Implementation Considerations:
- Focus on the VALIDATED database structure from research findings
- Query ONLY the confirmed active keys: `aiService.prompts`, `aiService.generations`, `composer.composerData`
- Handle the 100-message truncation limit with appropriate warnings
- Use Unix millisecond timestamps for chronological ordering
- Implement prompt-to-response correlation via timestamp matching
- Provide robust error handling with clear error messages
- Implement comprehensive logging for debugging
- Apply caching for performance optimization where appropriate

# Test Strategy:
The implementation will be verified through a comprehensive testing approach:

1. **Unit Tests**:
```python
def test_query_cursor_chat_database():
    """Test the main query function with a mock database."""
    # Setup mock database with test data based on validated structure
    mock_db_path = setup_mock_cursor_database()
    
    # Test with explicit path
    conversations = query_cursor_chat_database(mock_db_path)
    assert isinstance(conversations, list)
    assert len(conversations) > 0
    
    # Verify conversation structure
    for conv in conversations:
        assert "id" in conv
        assert "title" in conv
        assert "messages" in conv
        assert "truncation_warning" in conv
        
        # Verify message structure
        for msg in conv["messages"]:
            assert "role" in msg
            assert "content" in msg
            assert "id" in msg
            assert "timestamp" in msg
            if msg != conv["messages"][0]:  # All but first message should have parent_id
                assert "parent_id" in msg
            
    # Test error handling with invalid path
    with pytest.raises(CursorDatabaseError):
        query_cursor_chat_database("/invalid/path")
```

2. **Data Processing Tests**:
```python
def test_process_cursor_chat_data():
    """Test processing of raw database data into structured conversations."""
    # Mock data based on validated structure
    mock_prompts = [(
        "aiService.prompts", 
        json.dumps([{
            "text": "Hello", 
            "commandType": 4,
            "unixMs": 1620000000000
        }])
    )]
    
    mock_responses = [(
        "aiService.generations", 
        json.dumps([{
            "textDescription": "Hi there", 
            "type": "composer",
            "unixMs": 1620000010000,
            "generationUUID": "test-uuid-1"
        }])
    )]
    
    mock_metadata = [(
        "composer.composerData", 
        json.dumps({"workspaceName": "Test Workspace"})
    )]
    
    result = _process_cursor_chat_data(mock_prompts, mock_responses, mock_metadata)
    assert len(result) == 1
    assert result[0]["title"] == "Test Workspace"
    assert len(result[0]["messages"]) == 2
    assert result[0]["messages"][0]["role"] == "user"
    assert result[0]["messages"][1]["role"] == "assistant"
    assert result[0]["messages"][1]["parent_id"] == result[0]["messages"][0]["id"]
    assert result[0]["messages"][0]["timestamp"] < result[0]["messages"][1]["timestamp"]
```

3. **Truncation Detection Tests**:
```python
def test_truncation_detection():
    """Test detection of the 100-message truncation limit."""
    # Generate exactly 100 AI responses
    mock_responses = []
    for i in range(100):
        mock_responses.append((
            "aiService.generations", 
            json.dumps({
                "textDescription": f"Response {i}", 
                "type": "composer",
                "unixMs": 1620000000000 + (i * 1000),
                "generationUUID": f"test-uuid-{i}"
            })
        ))
    
    # Process with minimal other data
    result = _process_cursor_chat_data([], mock_responses, [])
    assert result[0]["truncation_warning"] == True
    
    # Test with fewer messages
    result = _process_cursor_chat_data([], mock_responses[:50], [])
    assert result[0]["truncation_warning"] == False
```

4. **Integration Tests**:
```python
def test_integration_with_sqlite_reader():
    """Test integration with the SQLite reader function."""
    # Mock the workspace detection
    with patch("mcp.cursor_db.get_cursor_database_path") as mock_get_path:
        mock_get_path.return_value = setup_mock_cursor_database()
        
        # Test the query function without explicit path
        conversations = query_cursor_chat_database()
        assert isinstance(conversations, list)
        assert len(conversations) > 0
```

5. **Telemetry Tests**:
```python
def test_telemetry_integration():
    """Test telemetry integration in the database query function."""
    # Setup telemetry collector
    collector = TelemetryCollector()
    
    # Mock database to return test data
    with patch("mcp.cursor_db.query_cursor_chat_database") as mock_query:
        mock_query.return_value = [{
            "id": "test", 
            "title": "Test", 
            "messages": [],
            "truncation_warning": True
        }]
        
        # Call the function with telemetry
        result = query_cursor_chat_database_with_telemetry()
        
        # Verify telemetry events
        events = collector.get_events()
        assert any(e["name"] == "cursor_db_query_success" for e in events)
        success_event = next(e for e in events if e["name"] == "cursor_db_query_success")
        assert success_event["properties"]["truncation_warning"] == True
        
    # Test failure case
    with patch("mcp.cursor_db.query_cursor_chat_database") as mock_query:
        mock_query.side_effect = Exception("Test error")
        
        # Call should raise the exception
        with pytest.raises(Exception):
            query_cursor_chat_database_with_telemetry()
            
        # Verify failure telemetry
        events = collector.get_events()
        assert any(e["name"] == "cursor_db_query_failure" for e in events)
```

6. **Performance Tests**:
```python
def test_performance_with_large_dataset():
    """Test performance with a large chat history dataset."""
    # Generate large mock dataset based on validated structure
    large_db_path = setup_large_mock_cursor_database(
        prompt_count=50,
        response_count=50,
        with_timestamps=True
    )
    
    # Measure execution time
    start_time = time.time()
    conversations = query_cursor_chat_database(large_db_path)
    execution_time = time.time() - start_time
    
    # Verify results
    assert len(conversations) == 1
    assert len(conversations[0]["messages"]) == 100
    
    # Performance assertion (adjust threshold as needed)
    assert execution_time < 2.0, f"Query took too long: {execution_time} seconds"
```

7. **Manual Testing Checklist**:
- Verify function works with actual Cursor installations on different platforms
- Test with different Cursor versions to ensure compatibility
- Validate parsing with real-world examples from the research document
- Check memory usage with large chat histories
- Verify error messages are clear and actionable
- Confirm truncation warnings appear when appropriate
- Validate timestamp-based message ordering matches actual conversation flow

# Subtasks:
## 1. Create Core Query Execution Module [done]
### Dependencies: None
### Description: Implement the fundamental database query execution functionality with proper connection management and error handling.
### Details:
TDD Steps:

**WRITE TESTS FIRST**
- Create tests/unit/test_cursor_db_query_executor.py
- Test execute_cursor_query(db_path, query, params) function
- Test parameterized query safety (SQL injection prevention)
- Test connection timeout handling (default 5s)
- Test error cases: invalid db path, malformed query, locked database
- Mock sqlite3 connections and cursors
- RUN TESTS - VERIFY THEY FAIL

**GET APPROVAL FOR DESIGN CHOICES**
- PAUSE FOR MANUAL APPROVAL: Query timeout strategy (5s default, configurable?)
- PAUSE FOR MANUAL APPROVAL: Return format (list of tuples vs dict vs custom type)
- PAUSE FOR MANUAL APPROVAL: Connection pooling needs (or keep it simple?)

**IMPLEMENT FUNCTIONALITY**
- Create src/mcp_commit_story/cursor_db/query_executor.py
- Implement execute_cursor_query() with parameterized query support
- Add connection management with proper cleanup
- Implement query timeout handling
- Add comprehensive error wrapping in custom exceptions
- RUN TESTS - VERIFY THEY PASS

**DOCUMENT AND COMPLETE**
- Add documentation to cursor-chat-database-research.md if needed
- Update module docstrings
- Run the entire test suite
- MARK COMPLETE
<info added on 2025-06-25T08:53:53.602Z>
**Design Choice Decisions for 46.1 - Core Query Execution Module:**

✅ **Query Timeout Strategy: Use a fixed 5-second timeout (not configurable)**
- Rationale: This is just a local SQLite query. If it takes > 5s, something is seriously wrong
- No need for configuration complexity

✅ **Return Format: Use list of tuples - SQLite's native format**
- Include type hints for clarity: List[Tuple[Any, ...]]
- No dict conversion or custom types at this low level
- Let higher-level functions handle any formatting needs

✅ **Connection Pooling: No pooling - keep it simple**
- One connection per query with proper cleanup
- SQLite handles concurrent reads well
- Avoids unnecessary complexity for a local database

These decisions are documented and ready for implementation when resuming work.
</info added on 2025-06-25T08:53:53.602Z>
<info added on 2025-06-25T21:41:01.267Z>
**IMPLEMENTATION COMPLETE**

**Final Implementation Summary:**

1. **Created comprehensive test suite** (tests/unit/test_cursor_db_query_executor.py):
   - 17 test cases covering all scenarios
   - Success cases: simple queries, parameterized queries, empty results
   - Error handling: invalid paths, malformed SQL, locked database, parameter mismatches 
   - Parameter safety: SQL injection prevention, None handling, empty tuples
   - Return format validation: List[Tuple[Any, ...]] compliance
   - Connection management: 5-second timeout, context manager cleanup

2. **Implemented core query executor** (src/mcp_commit_story/cursor_db/query_executor.py):
   - Function signature: `execute_cursor_query(db_path, query, parameters=None) -> List[Tuple[Any, ...]]`
   - Fixed 5-second timeout as per approved design
   - Proper context manager usage for connection cleanup
   - Comprehensive error wrapping in custom exceptions (CursorDatabaseAccessError, CursorDatabaseQueryError)
   - Exception type detection by name to handle mocked tests
   - SQL injection prevention through parameterized queries

3. **Integration completed**:
   - Added to cursor_db package __init__.py exports
   - All 17 new tests pass ✅
   - Full test suite passes (867 tests) with no regressions ✅
   - Function successfully importable from package ✅

4. **Documentation updated**:
   - Added implementation section to docs/cursor-chat-database-research.md ✅
   - Comprehensive module docstrings included ✅
   - Usage examples provided ✅

**Key Implementation Details:**
- Uses sqlite3.connect() with context manager for automatic cleanup
- Exception handling detects SQLite error types by name for test compatibility  
- Returns raw SQLite results (List[Tuple[Any, ...]]) as specified
- Follows approved design choices exactly: no connection pooling, fixed timeout, comprehensive error wrapping

**Ready for use by subsequent subtasks 46.2, 46.3, etc.**
</info added on 2025-06-25T21:41:01.267Z>

## 2. Implement Message Data Extraction [done]
### Dependencies: 46.1
### Description: Create functions to extract and parse chat data from the ItemTable key-value structure.
### Details:
TDD Steps:

**WRITE TESTS FIRST**
- Create tests/unit/test_message_extraction.py
- Test extract_prompts_data(db_path) function
- Test extract_generations_data(db_path) function
- Test JSON parsing with malformed data handling
- Test handling of missing keys (aiService.prompts/generations not found)
- Mock database responses with real-world data structures
- RUN TESTS - VERIFY THEY FAIL

**GET APPROVAL FOR DESIGN CHOICES**
- PAUSE FOR MANUAL APPROVAL: Handling of malformed JSON (skip, error, or attempt repair?)
- PAUSE FOR MANUAL APPROVAL: Memory strategy for large chat histories
- PAUSE FOR MANUAL APPROVAL: Batch processing approach for 100+ messages

**IMPLEMENT FUNCTIONALITY**
- Create src/mcp_commit_story/cursor_db/message_extraction.py
- Implement extract_prompts_data() to get user messages
- Implement extract_generations_data() to get AI responses
- Add robust JSON parsing with error recovery
- Handle edge cases (empty data, missing keys)
- RUN TESTS - VERIFY THEY PASS

**DOCUMENT AND COMPLETE**
- Document data structures found
- Note any format variations discovered
- Run the entire test suite
- MARK COMPLETE

## 3. Create Message Reconstruction Logic [done]
### Dependencies: 46.2
### Description: Implement the logic to combine prompts and generations into chronologically ordered conversations.
### Details:
TDD Steps:

**WRITE TESTS FIRST**
- Create tests/unit/test_message_reconstruction.py
- Test reconstruct_chat_history(prompts, generations) function
- Test chronological ordering by unixMs timestamps
- Test message pairing (prompt → generation matching)
- Test handling of orphaned messages (prompt without generation)
- Test truncation detection (generations count = 100)
- RUN TESTS - VERIFY THEY FAIL

**GET APPROVAL FOR DESIGN CHOICES**
- PAUSE FOR MANUAL APPROVAL: Message format structure (dict with role, content, timestamp)
- PAUSE FOR MANUAL APPROVAL: Handling of unpaired messages (include with warning?)
- PAUSE FOR MANUAL APPROVAL: Truncation warning strategy

**IMPLEMENT FUNCTIONALITY**
- Create src/mcp_commit_story/cursor_db/message_reconstruction.py
- Implement reconstruct_chat_history() with timestamp ordering
- Add prompt-to-generation pairing logic
- Implement truncation detection and warnings
- Create standardized message format with role indicators
- RUN TESTS - VERIFY THEY PASS

**DOCUMENT AND COMPLETE**
- Document message pairing algorithm
- Add examples of reconstructed conversations
- Run the entire test suite
- MARK COMPLETE
<info added on 2025-06-25T22:59:15.439Z>
**FINALIZED DESIGN CHOICES FOR 46.3:**

**1. Message Format Structure: Simple dict**
```python
{
    "role": "user" | "assistant",
    "content": "message text",
    "timestamp": 1746792719853,  # None for prompts
    "type": "composer" | "apply" | None,  # None for prompts
}
```

**2. Handling of Unpaired Messages: No pairing attempt**
- This is a **programmatic function with no AI involvement**
- Return **ALL messages** without trying to match them
- **Don't add special flags** or pairing fields (no "unpaired" flags)
- Let the **journal generation AI figure out conversation flow** later

**3. Truncation Warning Strategy: Clean metadata only**
```python
return {
    "messages": [...],  # All messages, keep extraction order
    "metadata": {
        "prompt_count": len(prompts),
        "generation_count": len(generations)
    }
}
```

**4. Message Ordering: Keep extraction order**
- Return prompts in the order they were extracted
- Return generations in the order they were extracted
- Preserve the original database order (most authentic view)
- DON'T attempt sorting by timestamp

**5. Content Mapping:**
- User: `prompt['text']` → `message['content']`
- AI: `generation['textDescription']` → `message['content']`
- No ID fields needed - keep it simple

**6. Documentation Approach: Code documentation only**
- Clear docstrings explaining lack of timestamp pairing
- Inline comments about why we're not matching prompts/generations
- Note about 100-generation capacity limit in docstring
- NO updates to Docs/PRD/Engineering Spec (save for 46.5 and 46.6)

**Example function signature:**
```python
def reconstruct_chat_history(prompts, generations):
    """
    Reconstruct chat history from a single database.
    
    Note: User prompts lack timestamps, so messages cannot be paired 
    chronologically. This function returns all messages without attempting 
    to match prompts to generations. The consuming AI will interpret the 
    conversation flow.
    
    If generation_count == 100, the database may be at capacity.
    Additional messages might exist in other workspace databases.
    
    Args:
        prompts: List of prompt dicts from extract_prompts_data()
        generations: List of generation dicts from extract_generations_data()
        
    Returns:
        dict with 'messages' list and 'metadata' dict
    """
```
</info added on 2025-06-25T22:59:15.439Z>
<info added on 2025-06-25T23:08:39.793Z>
**IMPLEMENTATION COMPLETED SUCCESSFULLY!**

**What was implemented:**
1. **Function created**: `reconstruct_chat_history()` in `src/mcp_commit_story/cursor_db/message_reconstruction.py`
2. **Simple message format**: Each message has `role`, `content`, `timestamp`, `type` fields
3. **No pairing logic**: Returns ALL messages without attempting chronological matching
4. **Clean metadata**: Just `prompt_count` and `generation_count`
5. **Extraction order preserved**: Prompts first, then generations (no sorting by timestamp)
6. **Malformed data handling**: Graceful skip with logging for missing required fields
7. **Package export**: Added to `cursor_db/__init__.py` for easy import

**TDD Verification:**
- All 16 comprehensive tests pass
- Function signature exactly matches specification
- Return structure validated (dict with 'messages' and 'metadata')
- Edge cases covered (empty data, malformed data, mixed data)
- Full test suite still passes (897 passed, 1 skipped, 22 xfailed)

**Key Implementation Details:**
- User prompts map: `prompt['text'] → content` (timestamp: None, type: None)
- AI generations map: `generation['textDescription'] → content` (with timestamp/type)
- Metadata counts original input lengths before filtering
- Clear documentation about 100-generation limitation and multi-database needs
- Logging warnings for malformed data fields

Ready for integration with downstream journal generation!
</info added on 2025-06-25T23:08:39.793Z>

## 4. Add Telemetry Instrumentation [done]
### Dependencies: 46.3
### Description: Add comprehensive telemetry to all query operations following telemetry standards.
### Details:
TDD Steps:

**WRITE TESTS FIRST**
- Create tests/unit/test_query_telemetry.py
- Test @trace_mcp_operation decorator integration on all public functions
- Test performance metrics collection for query operations
- Test error categorization for query-specific failures
- Test memory tracking for large result sets
- Test truncation detection metrics
- Mock telemetry backends to verify instrumentation calls
- RUN TESTS - VERIFY THEY FAIL

**GET APPROVAL FOR DESIGN CHOICES**
- PAUSE FOR MANUAL APPROVAL: Performance thresholds for query operations
- PAUSE FOR MANUAL APPROVAL: Query-specific telemetry attributes
- PAUSE FOR MANUAL APPROVAL: Sampling strategy for high-frequency queries

**IMPLEMENT FUNCTIONALITY**
- Add @trace_mcp_operation to all public functions
- Implement performance tracking with thresholds
- Add query result metrics (message count, date range, truncation)
- Track memory usage for large extractions
- Add cache hit/miss tracking if caching implemented
- Follow error categorization patterns from platform telemetry
- RUN TESTS - VERIFY THEY PASS

**DOCUMENT AND COMPLETE**
- Update telemetry documentation if needed
- Add query-specific metric examples
- Run the entire test suite
- MARK COMPLETE
<info added on 2025-06-25T23:38:06.532Z>
**DESIGN CHOICES APPROVED**

Performance Thresholds (milliseconds):
```python
TELEMETRY_THRESHOLDS = {
    "execute_cursor_query": 50,        # Basic SQL query
    "extract_prompts_data": 100,       # Query + JSON parsing
    "extract_generations_data": 100,   # Query + JSON parsing  
    "reconstruct_chat_history": 200,   # Processing + sorting
}
```

Query-Specific Telemetry Attributes:
- database_path: Which database was queried
- prompt_count: Number of prompts extracted
- generation_count: Number of generations extracted
- truncation_detected: Boolean if generation_count == 100
- json_parse_errors: Count of skipped malformed entries
- query_duration_ms: Time taken for each operation

Sampling Strategy: No sampling initially
- These are local operations, not high-frequency
- Start with full telemetry to understand usage patterns
- Can add sampling later if needed

Documentation: Code documentation only
- Add docstrings explaining what metrics are tracked
- Include comments about why certain thresholds were chosen
- No updates to Docs/PRD/Engineering Spec needed (internal telemetry)

Implementation Pattern: Follow Task 45.6 telemetry patterns
- Use @trace_mcp_operation decorator on all public functions
- Apply to three modules: query_executor.py, message_extraction.py, message_reconstruction.py
- Reference completed Task 45.6 implementation for consistent patterns
</info added on 2025-06-25T23:38:06.532Z>

## 5. Implement High-Level Query Function [done]
### Dependencies: 46.4
### Description: Create the main query_cursor_chat_database() function that orchestrates all components.
### Details:
TDD Steps:

**WRITE TESTS FIRST**
- Create tests/unit/test_query_cursor_chat_database.py
- Test full workflow: connection → extraction → reconstruction
- Test with real-world database structures
- Test performance with large chat histories
- Test comprehensive error handling
- Test optional parameters (workspace_path, time_range)
- RUN TESTS - VERIFY THEY FAIL

**GET APPROVAL FOR DESIGN CHOICES**
- PAUSE FOR MANUAL APPROVAL: Function signature and optional parameters
- PAUSE FOR MANUAL APPROVAL: Return format for chat history
- PAUSE FOR MANUAL APPROVAL: Performance optimization strategies

**IMPLEMENT FUNCTIONALITY**
- Update src/mcp_commit_story/cursor_db/__init__.py with main function
- Implement query_cursor_chat_database() orchestrating all components
- Add workspace path resolution integration
- Add performance optimization (lazy loading, pagination?)
- Implement comprehensive telemetry
- RUN TESTS - VERIFY THEY PASS

**DOCUMENT AND COMPLETE**
- Update cursor-database-setup.md with usage examples
- Document performance characteristics
- Run the entire test suite
- MARK COMPLETE
<info added on 2025-06-26T00:25:29.272Z>
## Complete Implementation Plan for Task 46.5

### Design Decisions

**Function Purpose & Context:**
- Function designed for Python interpreter execution (git hooks, background processes), not AI assistant interaction
- Provides programmatic access to cursor chat data for automation workflows
- First user-facing API function in cursor_db package

**Function Signature:**
- Minimal signature: `def query_cursor_chat_database() -> Dict` (no parameters)
- No workspace path parameter - function will auto-detect workspace using existing platform detection
- Returns Dict format for easy JSON serialization and programmatic consumption

**Return Format Enhancement:**
- Extends reconstruct_chat_history() format with workspace_info metadata
- Structure:
  ```python
  {
    "workspace_info": {
      "workspace_path": str,
      "database_path": str, 
      "last_updated": str,
      "total_messages": int
    },
    "chat_history": [...] # existing reconstruct_chat_history format
  }
  ```

**Performance & Caching:**
- No caching for initial implementation (keep simple)
- Performance threshold: 500ms (sum of component thresholds: 50+100+100+200+overhead)
- Will orchestrate existing components: execute_cursor_query + extract functions + reconstruct

**Error Handling:**
- Graceful handling of missing workspace/database
- Return empty structure with error indicators rather than raising exceptions
- Maintain telemetry tracking for all error scenarios

### TDD Implementation Steps

1. **Write Tests First:**
   - Create tests/unit/test_query_cursor_chat_database.py
   - Test successful data retrieval with workspace_info
   - Test missing database graceful handling
   - Test empty database scenarios
   - Test telemetry instrumentation (@trace_mcp_operation decorator)
   - Test performance threshold tracking (500ms)

2. **Run Tests to Verify Failure:**
   - Confirm tests fail for the right reasons (function doesn't exist)

3. **Implement Core Functionality:**
   - Add function to cursor_db/__init__.py for easy import
   - Orchestrate existing components:
     - Use platform detection to find workspace
     - Call extract_prompts_data() and extract_generations_data()
     - Call reconstruct_chat_history()
     - Add workspace_info metadata wrapper
   - Handle all error scenarios gracefully

4. **Add Telemetry Instrumentation:**
   - Apply @trace_mcp_operation("cursor_db.query_chat_database") decorator
   - Track telemetry attributes:
     - workspace_path, database_path, total_messages
     - query_duration_ms, threshold_exceeded (500ms)
     - error.type, error.category for failure cases

5. **Run Tests to Verify Success:**
   - All tests should pass
   - Verify telemetry data collection
   - Confirm graceful error handling

6. **Add Comprehensive Documentation:**
   - Detailed docstring with usage examples
   - Document return format structure
   - Explain error scenarios and return values
   - Include performance considerations

7. **Mark Task Complete:**
   - Verify all requirements met
   - Update task status to 'done'

### Documentation Strategy

**Code Documentation Focus:**
- Comprehensive function docstring as primary documentation
- First user-facing API function requires exemplary documentation
- Include practical usage examples for Python interpreter context
- Document return format with type hints and structure examples
- Explain error scenarios and expected return values
- Note performance characteristics and thresholds

**Documentation Scope:**
- Code documentation only for this task (docstrings and comments)
- No updates to Docs/PRD/Engineering Spec (deferred to Task 46.8)
- Focus on making function self-documenting for developers

**Docstring Requirements:**
- Usage examples showing typical import and call patterns
- Complete return format documentation with example output
- Error handling scenarios and return values
- Performance notes about 500ms threshold
- Integration notes for git hooks and automation contexts

**Example Usage Documentation:**
```python
# Example for docstring:
from mcp_commit_story.cursor_db import query_cursor_chat_database

# Get complete chat history with workspace metadata
result = query_cursor_chat_database()
if result['workspace_info']['total_messages'] > 0:
    # Process chat history
    for message in result['chat_history']:
        # Handle message data
```
</info added on 2025-06-26T00:25:29.272Z>

## 6. Integration Testing and Documentation [pending]
### Dependencies: 46.5
### Description: Comprehensive integration testing and final documentation completion.
### Details:
TDD Steps:

**WRITE TESTS FIRST**
- Create tests/integration/test_cursor_db_full_integration.py
- Test complete flow with real Cursor database files
- Test edge cases: empty chats, corrupted data, large histories
- Test error recovery and graceful degradation
- Test telemetry data quality across full integration
- RUN TESTS - VERIFY THEY FAIL

**GET APPROVAL FOR DESIGN CHOICES**
- PAUSE FOR MANUAL APPROVAL: Final documentation structure
- PAUSE FOR MANUAL APPROVAL: Example usage patterns for users
- PAUSE FOR MANUAL APPROVAL: Performance benchmark expectations

**IMPLEMENT FUNCTIONALITY**
- Create integration test fixtures with real data
- Implement any missing error handling discovered in integration
- Add final optimizations based on real-world testing
- Verify telemetry data quality
- RUN TESTS - VERIFY THEY PASS

**DOCUMENT AND COMPLETE**
- Create comprehensive usage examples in docs/
- Document known limitations and edge cases
- Add troubleshooting guide
- Create performance benchmarks documentation
- Update main README with new functionality
- Run complete test suite (unit + integration)
- MARK COMPLETE

## 7. Handle Multiple Database Discovery for Complete History [deferred]
### Dependencies: 46.2
### Description: Discover and extract data from all Cursor databases for a workspace to handle database rotation after 100 generations
### Details:
**PURPOSE:**
Handle Cursor's database rotation when it hits 100 generations by discovering all related databases for a workspace and extracting data from each.

**CRITICAL INSIGHT:**
When Cursor hits 100 generations, it likely creates a new database. Current implementation only handles single databases, missing chat history in rotated databases.

**DESIGN CHOICES:**

**Return Structure:** Simple list of database results
```python
[
    {
        "database_path": "/path/db1.vscdb", 
        "prompts": [...],
        "generations": [...]
    },
    {
        "database_path": "/path/db2.vscdb",
        "prompts": [...], 
        "generations": [...]
    }
]
```

**Database Discovery:** Search for all state.vscdb files in workspace subdirectories
- Don't assume naming patterns or numbering schemes
- Search workspace storage directory recursively
- Find all state.vscdb files regardless of subdirectory structure

**Scope:** Just discovery and extraction
- Find all databases for a workspace
- Extract prompts and generations from each using existing 46.2 functions
- Return list of results
- NO merging, NO chronological ordering attempts
- Let journal AI figure out how to use multiple database results

**Error Handling:** Skip bad databases, continue processing
- Log warnings for inaccessible/corrupted databases
- Return partial results from successful databases
- Don't fail entire operation due to one bad database

**LIMITATION ACKNOWLEDGMENT:**
Cannot merge chronologically due to missing prompt timestamps. Return fragmented data and let consumers handle multiple database results appropriately.

**IMPLEMENTATION APPROACH:**
1. Create function to discover all workspace databases
2. Reuse extract_prompts_data() and extract_generations_data() from Task 46.2
3. Return simple list structure with database source tracking
4. Add comprehensive error handling with partial result support

## 8. Comprehensive Documentation [pending]
### Dependencies: 46.5
### Description: Create comprehensive documentation for the cursor_db package now that the implementation is complete.
### Details:
Create docs/cursor-db-api-guide.md with:

API usage examples for query_cursor_chat_database()
Complete workflow examples
Troubleshooting common issues
Performance considerations


Update docs/cursor-chat-database-research.md with:

Architecture overview of the implemented cursor_db package
How all the components work together
Integration patterns


Update Engineering Spec with:

cursor_db package architecture
API design decisions
Error handling strategy

