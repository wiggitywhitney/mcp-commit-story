# Task ID: 46
# Title: Implement Direct Database Query Function
# Status: in-progress
# Dependencies: None
# Priority: medium
# Description: Create a function to query the Cursor chat database and extract complete conversation history with proper parsing and error handling, based on validated research findings.
# Details:
This task implements a robust database query function that extracts comprehensive chat data from Cursor's SQLite database, following the validated research findings in `docs/cursor-chat-database-research.md`:

1. **Core Query Function Implementation**:
```python
@trace_mcp_operation
def query_cursor_chat_database(workspace_path=None):
    """
    Query the Cursor chat database to extract complete conversation history.
    
    Args:
        workspace_path: Optional path to workspace. If None, uses detected workspace.
        
    Returns:
        List of conversation objects with structured message history
        
    Raises:
        CursorDatabaseError: When database access or parsing fails
    """
    try:
        # Get database path using the SQLite Reader function
        db_path = get_cursor_database_path(workspace_path)
        
        # Connect to database
        connection = sqlite3.connect(db_path)
        cursor = connection.cursor()
        
        # Query the confirmed active keys based on research findings
        user_prompts = _query_table_by_key(cursor, "ItemTable", "aiService.prompts")
        ai_responses = _query_table_by_key(cursor, "ItemTable", "aiService.generations")
        metadata = _query_table_by_key(cursor, "ItemTable", "composer.composerData")
        
        # Process the data into conversations
        conversations = _process_cursor_chat_data(user_prompts, ai_responses, metadata)
        
        # Check for potential truncation (100-message limit)
        if len(ai_responses) >= 100:
            logger.warning("Detected 100 AI responses - data may be truncated due to Cursor's message limit")
            conversations[0]["truncation_warning"] = True
        
        connection.close()
        return conversations
        
    except Exception as e:
        logger.error(f"Error querying Cursor chat database: {str(e)}")
        raise CursorDatabaseError(f"Failed to query chat database: {str(e)}")
```

2. **Helper Functions for Database Access**:
```python
@trace_mcp_operation
def _query_table_by_key(cursor, table_name, key_value):
    """Query a specific table by key value and return results."""
    try:
        cursor.execute(f"SELECT key, value FROM {table_name} WHERE key = ?", (key_value,))
        results = cursor.fetchall()
        return results
    except sqlite3.Error as e:
        logger.warning(f"Error querying {table_name} with key {key_value}: {str(e)}")
        return []
```

3. **Data Processing Function**:
```python
@trace_mcp_operation
def _process_cursor_chat_data(user_prompts, ai_responses, metadata):
    """Process the raw database data into structured conversations."""
    # Parse the raw data
    parsed_prompts = []
    for _, value in user_prompts:
        try:
            prompt_data = json.loads(value)
            if isinstance(prompt_data, list):
                for item in prompt_data:
                    if item.get("commandType") == 4:  # User prompt
                        parsed_prompts.append({
                            "text": item.get("text", ""),
                            "timestamp": item.get("unixMs", 0)
                        })
            elif prompt_data.get("commandType") == 4:  # Single user prompt
                parsed_prompts.append({
                    "text": prompt_data.get("text", ""),
                    "timestamp": prompt_data.get("unixMs", 0)
                })
        except json.JSONDecodeError:
            logger.warning("Failed to parse user prompt data")
    
    parsed_responses = []
    for _, value in ai_responses:
        try:
            response_data = json.loads(value)
            if isinstance(response_data, list):
                for item in response_data:
                    if item.get("type") == "composer":
                        parsed_responses.append({
                            "text": item.get("textDescription", ""),
                            "timestamp": item.get("unixMs", 0),
                            "uuid": item.get("generationUUID", str(uuid.uuid4()))
                        })
            elif response_data.get("type") == "composer":
                parsed_responses.append({
                    "text": response_data.get("textDescription", ""),
                    "timestamp": response_data.get("unixMs", 0),
                    "uuid": response_data.get("generationUUID", str(uuid.uuid4()))
                })
        except json.JSONDecodeError:
            logger.warning("Failed to parse AI response data")
    
    # Sort all messages by timestamp
    all_messages = []
    for prompt in parsed_prompts:
        all_messages.append({
            "role": "user",
            "content": prompt["text"],
            "timestamp": prompt["timestamp"],
            "id": str(uuid.uuid4())
        })
    
    for response in parsed_responses:
        all_messages.append({
            "role": "assistant",
            "content": response["text"],
            "timestamp": response["timestamp"],
            "id": response["uuid"]
        })
    
    # Sort by timestamp
    all_messages.sort(key=lambda x: x["timestamp"])
    
    # Assign parent_id based on message sequence
    for i in range(1, len(all_messages)):
        all_messages[i]["parent_id"] = all_messages[i-1]["id"]
    
    # Extract workspace metadata if available
    workspace_title = "Cursor Workspace"
    if metadata:
        try:
            metadata_json = json.loads(metadata[0][1])
            workspace_title = metadata_json.get("workspaceName", workspace_title)
        except (json.JSONDecodeError, IndexError):
            logger.warning("Failed to parse workspace metadata")
    
    # Create a single conversation object
    conversation = {
        "id": str(uuid.uuid4()),
        "title": workspace_title,
        "messages": all_messages,
        "truncation_warning": False  # Will be set to True if 100-message limit detected
    }
    
    return [conversation]
```

4. **Error Handling and Custom Exceptions**:
```python
class CursorDatabaseError(Exception):
    """Exception raised for errors in the Cursor database operations."""
    pass
```

5. **Caching Implementation**:
```python
@lru_cache(maxsize=32)
@trace_mcp_operation
def get_cached_conversations(workspace_path=None):
    """
    Cached version of query_cursor_chat_database to improve performance
    for repeated calls.
    """
    return query_cursor_chat_database(workspace_path)
```

6. **Telemetry Integration**:
```python
@trace_mcp_operation
def query_cursor_chat_database_with_telemetry(workspace_path=None):
    """Wrapper with telemetry for the database query function."""
    start_time = time.time()
    try:
        result = query_cursor_chat_database(workspace_path)
        telemetry.record_event(
            "cursor_db_query_success",
            {
                "duration_ms": (time.time() - start_time) * 1000,
                "conversation_count": len(result),
                "message_count": sum(len(conv["messages"]) for conv in result),
                "truncation_warning": any(conv.get("truncation_warning", False) for conv in result)
            }
        )
        return result
    except Exception as e:
        telemetry.record_event(
            "cursor_db_query_failure",
            {
                "duration_ms": (time.time() - start_time) * 1000,
                "error_type": type(e).__name__,
                "error_message": str(e)
            }
        )
        raise
```

Implementation Considerations:
- Focus on the VALIDATED database structure from research findings
- Query ONLY the confirmed active keys: `aiService.prompts`, `aiService.generations`, `composer.composerData`
- Handle the 100-message truncation limit with appropriate warnings
- Use Unix millisecond timestamps for chronological ordering
- Implement prompt-to-response correlation via timestamp matching
- Provide robust error handling with clear error messages
- Implement comprehensive logging for debugging
- Apply caching for performance optimization where appropriate

# Test Strategy:
The implementation will be verified through a comprehensive testing approach:

1. **Unit Tests**:
```python
def test_query_cursor_chat_database():
    """Test the main query function with a mock database."""
    # Setup mock database with test data based on validated structure
    mock_db_path = setup_mock_cursor_database()
    
    # Test with explicit path
    conversations = query_cursor_chat_database(mock_db_path)
    assert isinstance(conversations, list)
    assert len(conversations) > 0
    
    # Verify conversation structure
    for conv in conversations:
        assert "id" in conv
        assert "title" in conv
        assert "messages" in conv
        assert "truncation_warning" in conv
        
        # Verify message structure
        for msg in conv["messages"]:
            assert "role" in msg
            assert "content" in msg
            assert "id" in msg
            assert "timestamp" in msg
            if msg != conv["messages"][0]:  # All but first message should have parent_id
                assert "parent_id" in msg
            
    # Test error handling with invalid path
    with pytest.raises(CursorDatabaseError):
        query_cursor_chat_database("/invalid/path")
```

2. **Data Processing Tests**:
```python
def test_process_cursor_chat_data():
    """Test processing of raw database data into structured conversations."""
    # Mock data based on validated structure
    mock_prompts = [(
        "aiService.prompts", 
        json.dumps([{
            "text": "Hello", 
            "commandType": 4,
            "unixMs": 1620000000000
        }])
    )]
    
    mock_responses = [(
        "aiService.generations", 
        json.dumps([{
            "textDescription": "Hi there", 
            "type": "composer",
            "unixMs": 1620000010000,
            "generationUUID": "test-uuid-1"
        }])
    )]
    
    mock_metadata = [(
        "composer.composerData", 
        json.dumps({"workspaceName": "Test Workspace"})
    )]
    
    result = _process_cursor_chat_data(mock_prompts, mock_responses, mock_metadata)
    assert len(result) == 1
    assert result[0]["title"] == "Test Workspace"
    assert len(result[0]["messages"]) == 2
    assert result[0]["messages"][0]["role"] == "user"
    assert result[0]["messages"][1]["role"] == "assistant"
    assert result[0]["messages"][1]["parent_id"] == result[0]["messages"][0]["id"]
    assert result[0]["messages"][0]["timestamp"] < result[0]["messages"][1]["timestamp"]
```

3. **Truncation Detection Tests**:
```python
def test_truncation_detection():
    """Test detection of the 100-message truncation limit."""
    # Generate exactly 100 AI responses
    mock_responses = []
    for i in range(100):
        mock_responses.append((
            "aiService.generations", 
            json.dumps({
                "textDescription": f"Response {i}", 
                "type": "composer",
                "unixMs": 1620000000000 + (i * 1000),
                "generationUUID": f"test-uuid-{i}"
            })
        ))
    
    # Process with minimal other data
    result = _process_cursor_chat_data([], mock_responses, [])
    assert result[0]["truncation_warning"] == True
    
    # Test with fewer messages
    result = _process_cursor_chat_data([], mock_responses[:50], [])
    assert result[0]["truncation_warning"] == False
```

4. **Integration Tests**:
```python
def test_integration_with_sqlite_reader():
    """Test integration with the SQLite reader function."""
    # Mock the workspace detection
    with patch("mcp.cursor_db.get_cursor_database_path") as mock_get_path:
        mock_get_path.return_value = setup_mock_cursor_database()
        
        # Test the query function without explicit path
        conversations = query_cursor_chat_database()
        assert isinstance(conversations, list)
        assert len(conversations) > 0
```

5. **Telemetry Tests**:
```python
def test_telemetry_integration():
    """Test telemetry integration in the database query function."""
    # Setup telemetry collector
    collector = TelemetryCollector()
    
    # Mock database to return test data
    with patch("mcp.cursor_db.query_cursor_chat_database") as mock_query:
        mock_query.return_value = [{
            "id": "test", 
            "title": "Test", 
            "messages": [],
            "truncation_warning": True
        }]
        
        # Call the function with telemetry
        result = query_cursor_chat_database_with_telemetry()
        
        # Verify telemetry events
        events = collector.get_events()
        assert any(e["name"] == "cursor_db_query_success" for e in events)
        success_event = next(e for e in events if e["name"] == "cursor_db_query_success")
        assert success_event["properties"]["truncation_warning"] == True
        
    # Test failure case
    with patch("mcp.cursor_db.query_cursor_chat_database") as mock_query:
        mock_query.side_effect = Exception("Test error")
        
        # Call should raise the exception
        with pytest.raises(Exception):
            query_cursor_chat_database_with_telemetry()
            
        # Verify failure telemetry
        events = collector.get_events()
        assert any(e["name"] == "cursor_db_query_failure" for e in events)
```

6. **Performance Tests**:
```python
def test_performance_with_large_dataset():
    """Test performance with a large chat history dataset."""
    # Generate large mock dataset based on validated structure
    large_db_path = setup_large_mock_cursor_database(
        prompt_count=50,
        response_count=50,
        with_timestamps=True
    )
    
    # Measure execution time
    start_time = time.time()
    conversations = query_cursor_chat_database(large_db_path)
    execution_time = time.time() - start_time
    
    # Verify results
    assert len(conversations) == 1
    assert len(conversations[0]["messages"]) == 100
    
    # Performance assertion (adjust threshold as needed)
    assert execution_time < 2.0, f"Query took too long: {execution_time} seconds"
```

7. **Manual Testing Checklist**:
- Verify function works with actual Cursor installations on different platforms
- Test with different Cursor versions to ensure compatibility
- Validate parsing with real-world examples from the research document
- Check memory usage with large chat histories
- Verify error messages are clear and actionable
- Confirm truncation warnings appear when appropriate
- Validate timestamp-based message ordering matches actual conversation flow

# Subtasks:
## 1. Create Core Query Execution Module [done]
### Dependencies: None
### Description: Implement the fundamental database query execution functionality with proper connection management and error handling.
### Details:
TDD Steps:

**WRITE TESTS FIRST**
- Create tests/unit/test_cursor_db_query_executor.py
- Test execute_cursor_query(db_path, query, params) function
- Test parameterized query safety (SQL injection prevention)
- Test connection timeout handling (default 5s)
- Test error cases: invalid db path, malformed query, locked database
- Mock sqlite3 connections and cursors
- RUN TESTS - VERIFY THEY FAIL

**GET APPROVAL FOR DESIGN CHOICES**
- PAUSE FOR MANUAL APPROVAL: Query timeout strategy (5s default, configurable?)
- PAUSE FOR MANUAL APPROVAL: Return format (list of tuples vs dict vs custom type)
- PAUSE FOR MANUAL APPROVAL: Connection pooling needs (or keep it simple?)

**IMPLEMENT FUNCTIONALITY**
- Create src/mcp_commit_story/cursor_db/query_executor.py
- Implement execute_cursor_query() with parameterized query support
- Add connection management with proper cleanup
- Implement query timeout handling
- Add comprehensive error wrapping in custom exceptions
- RUN TESTS - VERIFY THEY PASS

**DOCUMENT AND COMPLETE**
- Add documentation to cursor-chat-database-research.md if needed
- Update module docstrings
- Run the entire test suite
- MARK COMPLETE
<info added on 2025-06-25T08:53:53.602Z>
**Design Choice Decisions for 46.1 - Core Query Execution Module:**

✅ **Query Timeout Strategy: Use a fixed 5-second timeout (not configurable)**
- Rationale: This is just a local SQLite query. If it takes > 5s, something is seriously wrong
- No need for configuration complexity

✅ **Return Format: Use list of tuples - SQLite's native format**
- Include type hints for clarity: List[Tuple[Any, ...]]
- No dict conversion or custom types at this low level
- Let higher-level functions handle any formatting needs

✅ **Connection Pooling: No pooling - keep it simple**
- One connection per query with proper cleanup
- SQLite handles concurrent reads well
- Avoids unnecessary complexity for a local database

These decisions are documented and ready for implementation when resuming work.
</info added on 2025-06-25T08:53:53.602Z>
<info added on 2025-06-25T21:41:01.267Z>
**IMPLEMENTATION COMPLETE**

**Final Implementation Summary:**

1. **Created comprehensive test suite** (tests/unit/test_cursor_db_query_executor.py):
   - 17 test cases covering all scenarios
   - Success cases: simple queries, parameterized queries, empty results
   - Error handling: invalid paths, malformed SQL, locked database, parameter mismatches 
   - Parameter safety: SQL injection prevention, None handling, empty tuples
   - Return format validation: List[Tuple[Any, ...]] compliance
   - Connection management: 5-second timeout, context manager cleanup

2. **Implemented core query executor** (src/mcp_commit_story/cursor_db/query_executor.py):
   - Function signature: `execute_cursor_query(db_path, query, parameters=None) -> List[Tuple[Any, ...]]`
   - Fixed 5-second timeout as per approved design
   - Proper context manager usage for connection cleanup
   - Comprehensive error wrapping in custom exceptions (CursorDatabaseAccessError, CursorDatabaseQueryError)
   - Exception type detection by name to handle mocked tests
   - SQL injection prevention through parameterized queries

3. **Integration completed**:
   - Added to cursor_db package __init__.py exports
   - All 17 new tests pass ✅
   - Full test suite passes (867 tests) with no regressions ✅
   - Function successfully importable from package ✅

4. **Documentation updated**:
   - Added implementation section to docs/cursor-chat-database-research.md ✅
   - Comprehensive module docstrings included ✅
   - Usage examples provided ✅

**Key Implementation Details:**
- Uses sqlite3.connect() with context manager for automatic cleanup
- Exception handling detects SQLite error types by name for test compatibility  
- Returns raw SQLite results (List[Tuple[Any, ...]]) as specified
- Follows approved design choices exactly: no connection pooling, fixed timeout, comprehensive error wrapping

**Ready for use by subsequent subtasks 46.2, 46.3, etc.**
</info added on 2025-06-25T21:41:01.267Z>

## 2. Implement Message Data Extraction [done]
### Dependencies: 46.1
### Description: Create functions to extract and parse chat data from the ItemTable key-value structure.
### Details:
TDD Steps:

**WRITE TESTS FIRST**
- Create tests/unit/test_message_extraction.py
- Test extract_prompts_data(db_path) function
- Test extract_generations_data(db_path) function
- Test JSON parsing with malformed data handling
- Test handling of missing keys (aiService.prompts/generations not found)
- Mock database responses with real-world data structures
- RUN TESTS - VERIFY THEY FAIL

**GET APPROVAL FOR DESIGN CHOICES**
- PAUSE FOR MANUAL APPROVAL: Handling of malformed JSON (skip, error, or attempt repair?)
- PAUSE FOR MANUAL APPROVAL: Memory strategy for large chat histories
- PAUSE FOR MANUAL APPROVAL: Batch processing approach for 100+ messages

**IMPLEMENT FUNCTIONALITY**
- Create src/mcp_commit_story/cursor_db/message_extraction.py
- Implement extract_prompts_data() to get user messages
- Implement extract_generations_data() to get AI responses
- Add robust JSON parsing with error recovery
- Handle edge cases (empty data, missing keys)
- RUN TESTS - VERIFY THEY PASS

**DOCUMENT AND COMPLETE**
- Document data structures found
- Note any format variations discovered
- Run the entire test suite
- MARK COMPLETE

## 3. Create Message Reconstruction Logic [pending]
### Dependencies: 46.2
### Description: Implement the logic to combine prompts and generations into chronologically ordered conversations.
### Details:
TDD Steps:

**WRITE TESTS FIRST**
- Create tests/unit/test_message_reconstruction.py
- Test reconstruct_chat_history(prompts, generations) function
- Test chronological ordering by unixMs timestamps
- Test message pairing (prompt → generation matching)
- Test handling of orphaned messages (prompt without generation)
- Test truncation detection (generations count = 100)
- RUN TESTS - VERIFY THEY FAIL

**GET APPROVAL FOR DESIGN CHOICES**
- PAUSE FOR MANUAL APPROVAL: Message format structure (dict with role, content, timestamp)
- PAUSE FOR MANUAL APPROVAL: Handling of unpaired messages (include with warning?)
- PAUSE FOR MANUAL APPROVAL: Truncation warning strategy

**IMPLEMENT FUNCTIONALITY**
- Create src/mcp_commit_story/cursor_db/message_reconstruction.py
- Implement reconstruct_chat_history() with timestamp ordering
- Add prompt-to-generation pairing logic
- Implement truncation detection and warnings
- Create standardized message format with role indicators
- RUN TESTS - VERIFY THEY PASS

**DOCUMENT AND COMPLETE**
- Document message pairing algorithm
- Add examples of reconstructed conversations
- Run the entire test suite
- MARK COMPLETE

## 4. Add Telemetry Instrumentation [pending]
### Dependencies: 46.3
### Description: Add comprehensive telemetry to all query operations following telemetry standards.
### Details:
TDD Steps:

**WRITE TESTS FIRST**
- Create tests/unit/test_query_telemetry.py
- Test @trace_mcp_operation decorator integration on all public functions
- Test performance metrics collection for query operations
- Test error categorization for query-specific failures
- Test memory tracking for large result sets
- Test truncation detection metrics
- Mock telemetry backends to verify instrumentation calls
- RUN TESTS - VERIFY THEY FAIL

**GET APPROVAL FOR DESIGN CHOICES**
- PAUSE FOR MANUAL APPROVAL: Performance thresholds for query operations
- PAUSE FOR MANUAL APPROVAL: Query-specific telemetry attributes
- PAUSE FOR MANUAL APPROVAL: Sampling strategy for high-frequency queries

**IMPLEMENT FUNCTIONALITY**
- Add @trace_mcp_operation to all public functions
- Implement performance tracking with thresholds
- Add query result metrics (message count, date range, truncation)
- Track memory usage for large extractions
- Add cache hit/miss tracking if caching implemented
- Follow error categorization patterns from platform telemetry
- RUN TESTS - VERIFY THEY PASS

**DOCUMENT AND COMPLETE**
- Update telemetry documentation if needed
- Add query-specific metric examples
- Run the entire test suite
- MARK COMPLETE

## 5. Implement High-Level Query Function [pending]
### Dependencies: 46.4
### Description: Create the main query_cursor_chat_database() function that orchestrates all components.
### Details:
TDD Steps:

**WRITE TESTS FIRST**
- Create tests/unit/test_query_cursor_chat_database.py
- Test full workflow: connection → extraction → reconstruction
- Test with real-world database structures
- Test performance with large chat histories
- Test comprehensive error handling
- Test optional parameters (workspace_path, time_range)
- RUN TESTS - VERIFY THEY FAIL

**GET APPROVAL FOR DESIGN CHOICES**
- PAUSE FOR MANUAL APPROVAL: Function signature and optional parameters
- PAUSE FOR MANUAL APPROVAL: Return format for chat history
- PAUSE FOR MANUAL APPROVAL: Performance optimization strategies

**IMPLEMENT FUNCTIONALITY**
- Update src/mcp_commit_story/cursor_db/__init__.py with main function
- Implement query_cursor_chat_database() orchestrating all components
- Add workspace path resolution integration
- Add performance optimization (lazy loading, pagination?)
- Implement comprehensive telemetry
- RUN TESTS - VERIFY THEY PASS

**DOCUMENT AND COMPLETE**
- Update cursor-database-setup.md with usage examples
- Document performance characteristics
- Run the entire test suite
- MARK COMPLETE

## 6. Integration Testing and Documentation [pending]
### Dependencies: 46.5
### Description: Comprehensive integration testing and final documentation completion.
### Details:
TDD Steps:

**WRITE TESTS FIRST**
- Create tests/integration/test_cursor_db_full_integration.py
- Test complete flow with real Cursor database files
- Test edge cases: empty chats, corrupted data, large histories
- Test error recovery and graceful degradation
- Test telemetry data quality across full integration
- RUN TESTS - VERIFY THEY FAIL

**GET APPROVAL FOR DESIGN CHOICES**
- PAUSE FOR MANUAL APPROVAL: Final documentation structure
- PAUSE FOR MANUAL APPROVAL: Example usage patterns for users
- PAUSE FOR MANUAL APPROVAL: Performance benchmark expectations

**IMPLEMENT FUNCTIONALITY**
- Create integration test fixtures with real data
- Implement any missing error handling discovered in integration
- Add final optimizations based on real-world testing
- Verify telemetry data quality
- RUN TESTS - VERIFY THEY PASS

**DOCUMENT AND COMPLETE**
- Create comprehensive usage examples in docs/
- Document known limitations and edge cases
- Add troubleshooting guide
- Create performance benchmarks documentation
- Update main README with new functionality
- Run complete test suite (unit + integration)
- MARK COMPLETE

