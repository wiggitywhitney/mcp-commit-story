# Task ID: 38
# Title: Enhance journal_new_entry MCP Tool with Signal Processing Capability
# Status: pending
# Dependencies: 37
# Priority: high
# Description: Create a signal processing tool that enhances the existing journal_new_entry MCP tool to automatically discover and process pending signal files when manually triggered, completing the signal-based workflow.
# Details:
This task involves enhancing the journal_new_entry MCP tool to handle signal-based workflows:

1. **Update the journal_new_entry Tool**:
   - Modify the existing tool to check for pending signals before proceeding with normal operation
   - Implement signal discovery logic to scan `.mcp-commit-story/signals/` directory
   - Process signals in chronological order (oldest first)
   - Return appropriate journal file paths after processing
   - Clean up processed signal files
   - Return a helpful message if no signals exist: "No pending commits found. Make a git commit first."

2. **Create a Signal Processor Module**:
   ```python
   # signal_processor.py
   import os
   import json
   from pathlib import Path
   from datetime import datetime
   import logging
   
   logger = logging.getLogger(__name__)
   
   class SignalProcessor:
       def __init__(self, config):
           self.config = config
           self.signal_dir = Path(os.path.expanduser("~/.mcp-commit-story/signals/"))
           self.signal_dir.mkdir(parents=True, exist_ok=True)
           
       def get_pending_signals(self):
           """Discover all pending signal files and sort them chronologically."""
           signals = []
           for signal_file in self.signal_dir.glob("*.signal"):
               try:
                   created_time = signal_file.stat().st_mtime
                   signals.append((created_time, signal_file))
               except Exception as e:
                   logger.error(f"Error reading signal file {signal_file}: {e}")
           
           # Sort by creation time (oldest first)
           return [s[1] for s in sorted(signals, key=lambda x: x[0])]
           
       def process_signal(self, signal_file):
           """Process a single signal file and return the journal entry path."""
           try:
               with open(signal_file, 'r') as f:
                   signal_data = json.load(f)
                   
               # Extract necessary data from signal
               commit_hash = signal_data.get('commit_hash')
               commit_message = signal_data.get('commit_message')
               commit_timestamp = signal_data.get('timestamp')
               
               # Call journal orchestrator to generate entry
               from .journal_orchestrator import JournalOrchestrator
               orchestrator = JournalOrchestrator(self.config)
               journal_path = orchestrator.generate_entry(
                   commit_hash=commit_hash,
                   commit_message=commit_message,
                   timestamp=commit_timestamp
               )
               
               # Clean up the processed signal file
               signal_file.unlink()
               
               return journal_path
           except Exception as e:
               logger.error(f"Error processing signal {signal_file}: {e}")
               return None
               
       def process_all_signals(self):
           """Process all pending signals and return list of journal paths."""
           signals = self.get_pending_signals()
           if not signals:
               return []
               
           journal_paths = []
           for signal in signals:
               journal_path = self.process_signal(signal)
               if journal_path:
                   journal_paths.append(journal_path)
                   
           return journal_paths
   ```

3. **Integrate with journal_new_entry MCP Tool**:
   ```python
   @server.tool()
   async def journal_new_entry(request):
       """Create a new journal entry from the most recent commit."""
       try:
           config = load_config()
           
           # Check for pending signals first
           from .signal_processor import SignalProcessor
           processor = SignalProcessor(config)
           journal_paths = processor.process_all_signals()
           
           if journal_paths:
               # Return paths of generated journal entries
               return {
                   "status": "success",
                   "message": f"Generated {len(journal_paths)} journal entries from signals",
                   "journal_paths": journal_paths
               }
           else:
               # No signals found, inform user
               return {
                   "status": "warning",
                   "message": "No pending commits found. Make a git commit first."
               }
       except Exception as e:
           logger.error(f"Error in journal_new_entry: {e}")
           return {"status": "error", "message": str(e)}
   ```

4. **Update Documentation**:
   - Add documentation for the signal processing workflow
   - Update the README to explain the signal-based architecture
   - Document the integration between signal_management.py and journal_orchestrator.py

This implementation bridges the gap between signal_management.py (which creates signals) and journal_orchestrator.py (which generates entries), completing the signal-based architecture.

# Test Strategy:
To verify the correct implementation of the signal processing capability:

1. **Unit Tests**:
   - Create unit tests for the SignalProcessor class:
     ```python
     def test_get_pending_signals():
         # Setup: Create test signal files with different timestamps
         # Verify: Signals are returned in chronological order
         
     def test_process_signal():
         # Setup: Create a test signal file with known data
         # Verify: Journal entry is created with correct content
         # Verify: Signal file is deleted after processing
         
     def test_process_all_signals():
         # Setup: Create multiple test signal files
         # Verify: All signals are processed
         # Verify: Correct journal paths are returned
         # Verify: All signal files are cleaned up
     ```

2. **Integration Tests**:
   - Test the enhanced journal_new_entry tool:
     ```python
     def test_journal_new_entry_with_signals():
         # Setup: Create test signal files
         # Action: Call journal_new_entry tool
         # Verify: Correct response with journal paths
         # Verify: Signal files are processed and removed
         
     def test_journal_new_entry_without_signals():
         # Setup: Ensure no signal files exist
         # Action: Call journal_new_entry tool
         # Verify: Response indicates no pending commits
     ```

3. **Manual Testing**:
   - Create a test git repository
   - Make a commit to trigger signal creation
   - Manually invoke the journal_new_entry tool
   - Verify journal entry is created with correct content
   - Verify signal file is removed
   - Try invoking the tool again and verify the "No pending commits" message

4. **End-to-End Testing**:
   - Test the complete workflow:
     1. Make a git commit
     2. Verify signal file is created in .mcp-commit-story/signals/
     3. Run "Create a journal entry" command
     4. Verify journal entry is created
     5. Verify signal file is removed
     6. Run the command again and verify "No pending commits" message

5. **Error Handling Tests**:
   - Test with malformed signal files
   - Test with permission issues on signal directory
   - Test with network/API failures during journal generation

Document all test results and ensure the signal processing capability works reliably in all scenarios.
