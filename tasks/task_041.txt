# Task ID: 41
# Title: Implement Context Integration and AI-Powered Features
# Status: pending
# Dependencies: 39, 46
# Priority: medium
# Description: Update downstream components to process four distinct context sources (git, terminal, cursor chat database, synthesized summary) with proper fallback handling and implement AI-powered synthesized summary collection.
# Details:
This task enhances the journal generation system by integrating multiple context sources and adding AI-powered features for intelligent summarization.

1. **Four-Source Context Integration**:
   ```python
   @trace_mcp_operation
   def collect_integrated_context(commit_hash, config):
       """Collect and integrate context from all available sources"""
       context = {
           "git": None,
           "terminal": None, 
           "cursor_chat": None,
           "synthesized_summary": None
       }
       
       # Attempt to collect git context
       try:
           context["git"] = collect_git_context(commit_hash)
       except Exception as e:
           logger.warning(f"Failed to collect git context: {e}")
       
       # Attempt to collect terminal context
       try:
           context["terminal"] = collect_terminal_context(commit_hash)
       except Exception as e:
           logger.warning(f"Failed to collect terminal context: {e}")
       
       # Attempt to collect cursor chat context
       try:
           context["cursor_chat"] = collect_cursor_chat_context(commit_hash)
       except Exception as e:
           logger.warning(f"Failed to collect cursor chat context: {e}")
           
       # Attempt to collect synthesized summary
       try:
           context["synthesized_summary"] = collect_synthesized_summary(commit_hash)
       except Exception as e:
           logger.warning(f"Failed to collect synthesized summary: {e}")
       
       # Ensure at least one context source is available
       if all(v is None for v in context.values()):
           raise ContextCollectionError("All context sources failed")
           
       return context
   ```

2. **Fallback Handling**:
   ```python
   @trace_mcp_operation
   def process_context_with_fallback(context, config):
       """Process context with appropriate fallback strategies"""
       # Define fallback priority order
       fallback_order = config.get("context_fallback_order", 
                                  ["git", "cursor_chat", "synthesized_summary", "terminal"])
       
       # Find first available context based on priority
       primary_context = None
       for source in fallback_order:
           if context[source] is not None:
               primary_context = context[source]
               logger.info(f"Using {source} as primary context source")
               break
               
       if primary_context is None:
           raise ContextProcessingError("No valid context source available")
           
       # Enrich primary context with any available secondary sources
       enriched_context = enrich_primary_context(primary_context, context)
       
       return enriched_context
   ```

3. **Synthesized Summary Collection**:
   ```python
   @trace_mcp_operation
   def collect_synthesized_summary(commit_hash, config):
       """Generate AI-powered synthesized summary of development context"""
       # Collect available context for AI processing
       git_context = collect_git_context(commit_hash)
       chat_context = None
       
       try:
           chat_context = collect_cursor_chat_context(commit_hash)
       except Exception as e:
           logger.warning(f"Chat context unavailable for AI synthesis: {e}")
       
       # Prepare prompt for AI
       prompt = generate_synthesis_prompt(
           git_context=git_context,
           chat_context=chat_context,
           detail_level=config.get("ai_summary_detail_level", "medium"),
           focus_areas=config.get("ai_summary_focus_areas", ["implementation_decisions", "problem_solving"])
       )
       
       # Call AI with circuit breaker pattern
       max_retries = config.get("ai_max_retries", 3)
       retry_count = 0
       
       while retry_count < max_retries:
           try:
               response = call_ai_service(prompt, config)
               return parse_ai_synthesis_response(response)
           except RateLimitError:
               retry_count += 1
               wait_time = 2 ** retry_count  # Exponential backoff
               logger.warning(f"Rate limited, retrying in {wait_time}s")
               time.sleep(wait_time)
           except APIError as e:
               logger.error(f"AI service error: {e}")
               return None
       
       logger.error("Max retries exceeded for AI synthesis")
       return None
   ```

4. **Configuration Options**:
   ```python
   # Example configuration in config.yaml
   context_integration:
     fallback_order: ["git", "cursor_chat", "synthesized_summary", "terminal"]
     ai_summary:
       enabled: true
       detail_level: "medium"  # Options: minimal, medium, detailed
       focus_areas:
         - "implementation_decisions"
         - "problem_solving"
         - "code_relationships"
       max_tokens: 1024
       temperature: 0.7
       max_retries: 3
       timeout_seconds: 30
   ```

5. **Integration with Journal Generation**:
   ```python
   @trace_mcp_operation
   def generate_journal_entry(commit_hash, config):
       """Generate journal entry with enhanced context integration"""
       # Collect integrated context
       try:
           context = collect_integrated_context(commit_hash, config)
       except ContextCollectionError as e:
           logger.error(f"Context collection failed: {e}")
           # Fall back to basic journal generation
           return generate_basic_journal_entry(commit_hash)
       
       # Process context with fallback handling
       processed_context = process_context_with_fallback(context, config)
       
       # Generate enhanced journal entry
       entry = {
           "commit_hash": commit_hash,
           "timestamp": datetime.now().isoformat(),
           "content": generate_content_from_context(processed_context),
           "context_sources_used": [k for k, v in context.items() if v is not None],
           "primary_context_source": determine_primary_source(context, config)
       }
       
       # Add telemetry
       record_context_integration_telemetry(entry, context)
       
       return entry
   ```

6. **Telemetry Implementation**:
   ```python
   @trace_mcp_operation
   def record_context_integration_telemetry(entry, context):
       """Record telemetry for context integration"""
       telemetry = {
           "timestamp": datetime.now().isoformat(),
           "operation": "context_integration",
           "context_sources_available": [k for k, v in context.items() if v is not None],
           "context_sources_count": sum(1 for v in context.values() if v is not None),
           "ai_synthesis_used": context["synthesized_summary"] is not None,
           "cursor_chat_available": context["cursor_chat"] is not None,
           "content_length": len(entry["content"]) if "content" in entry else 0
       }
       
       # Record telemetry according to docs/telemetry.md
       TelemetryCollector.record("context_integration", telemetry)
   ```

Implementation Requirements:
- Follow strict TDD with failing tests first for all components
- Add @trace_mcp_operation decorators to all functions for proper tracing
- Implement comprehensive telemetry as defined in docs/telemetry.md
- Ensure backward compatibility with existing journal generation
- Add circuit breaker patterns for all external service calls
- Implement graceful degradation when services are unavailable

# Test Strategy:
The testing strategy for this task will follow a comprehensive approach to ensure all components work correctly:

1. **Unit Tests for Context Integration**:
   ```python
   def test_collect_integrated_context():
       # Mock all context collection functions
       with patch('collect_git_context') as mock_git, \
            patch('collect_terminal_context') as mock_terminal, \
            patch('collect_cursor_chat_context') as mock_chat, \
            patch('collect_synthesized_summary') as mock_summary:
           
           # Test successful collection from all sources
           mock_git.return_value = {"git": "data"}
           mock_terminal.return_value = {"terminal": "data"}
           mock_chat.return_value = {"chat": "data"}
           mock_summary.return_value = {"summary": "data"}
           
           result = collect_integrated_context("abc123", {})
           assert all(v is not None for v in result.values())
           
           # Test fallback when some sources fail
           mock_chat.side_effect = Exception("DB unavailable")
           mock_summary.side_effect = Exception("AI service down")
           
           result = collect_integrated_context("abc123", {})
           assert result["git"] is not None
           assert result["terminal"] is not None
           assert result["cursor_chat"] is None
           assert result["synthesized_summary"] is None
           
           # Test all sources failing
           mock_git.side_effect = Exception("Git error")
           mock_terminal.side_effect = Exception("Terminal error")
           
           with pytest.raises(ContextCollectionError):
               collect_integrated_context("abc123", {})
   ```

2. **Unit Tests for Fallback Handling**:
   ```python
   def test_process_context_with_fallback():
       # Test with all sources available
       context = {
           "git": {"git": "data"},
           "terminal": {"terminal": "data"},
           "cursor_chat": {"chat": "data"},
           "synthesized_summary": {"summary": "data"}
       }
       
       config = {"context_fallback_order": ["git", "cursor_chat", "synthesized_summary", "terminal"]}
       result = process_context_with_fallback(context, config)
       assert "git" in str(result)
       
       # Test with primary source missing
       context["git"] = None
       result = process_context_with_fallback(context, config)
       assert "chat" in str(result)
       
       # Test with only last fallback available
       context["cursor_chat"] = None
       context["synthesized_summary"] = None
       result = process_context_with_fallback(context, config)
       assert "terminal" in str(result)
       
       # Test with no sources available
       context["terminal"] = None
       with pytest.raises(ContextProcessingError):
           process_context_with_fallback(context, config)
   ```

3. **Unit Tests for AI Synthesis**:
   ```python
   def test_collect_synthesized_summary():
       # Mock dependencies
       with patch('collect_git_context') as mock_git, \
            patch('collect_cursor_chat_context') as mock_chat, \
            patch('call_ai_service') as mock_ai:
           
           mock_git.return_value = {"diff": "sample diff"}
           mock_chat.return_value = {"messages": ["sample chat"]}
           mock_ai.return_value = {"synthesis": "AI generated summary"}
           
           config = {"ai_summary_detail_level": "medium"}
           result = collect_synthesized_summary("abc123", config)
           assert result is not None
           assert "AI generated summary" in str(result)
           
           # Test rate limiting with retry
           mock_ai.side_effect = [RateLimitError(), {"synthesis": "retry worked"}]
           result = collect_synthesized_summary("abc123", config)
           assert result is not None
           assert "retry worked" in str(result)
           
           # Test max retries exceeded
           mock_ai.side_effect = RateLimitError()
           result = collect_synthesized_summary("abc123", config)
           assert result is None
   ```

4. **Integration Tests**:
   ```python
   def test_journal_generation_with_integrated_context():
       # Create test git repository
       repo = create_test_repo()
       commit_hash = create_test_commit(repo)
       
       # Create test cursor chat database
       create_test_cursor_db()
       
       # Configure test environment
       config = {
           "context_fallback_order": ["git", "cursor_chat", "synthesized_summary", "terminal"],
           "ai_summary": {
               "enabled": True,
               "detail_level": "medium"
           }
       }
       
       # Test with all sources available
       entry = generate_journal_entry(commit_hash, config)
       assert entry is not None
       assert "commit_hash" in entry
       assert "context_sources_used" in entry
       assert len(entry["context_sources_used"]) > 0
       
       # Test with cursor chat unavailable
       remove_test_cursor_db()
       entry = generate_journal_entry(commit_hash, config)
       assert entry is not None
       assert "cursor_chat" not in entry["context_sources_used"]
       
       # Verify telemetry was recorded
       telemetry = TelemetryCollector.get_records("context_integration")
       assert len(telemetry) > 0
   ```

5. **Circuit Breaker Tests**:
   ```python
   def test_ai_service_circuit_breaker():
       # Mock AI service to fail consistently
       with patch('call_ai_service') as mock_ai:
           mock_ai.side_effect = APIError("Service unavailable")
           
           # Verify circuit breaker prevents excessive retries
           start_time = time.time()
           result = collect_synthesized_summary("abc123", {})
           end_time = time.time()
           
           assert result is None
           assert end_time - start_time < 5  # Should fail fast, not retry indefinitely
   ```

6. **Performance Tests**:
   ```python
   def test_context_integration_performance():
       # Test with varying context sizes
       for size in ["small", "medium", "large"]:
           # Generate test data of appropriate size
           git_context = generate_test_git_context(size)
           chat_context = generate_test_chat_context(size)
           
           # Measure performance
           start_time = time.time()
           context = {
               "git": git_context,
               "terminal": None,
               "cursor_chat": chat_context,
               "synthesized_summary": None
           }
           process_context_with_fallback(context, {})
           end_time = time.time()
           
           # Record performance metrics
           TelemetryCollector.record("performance_test", {
               "operation": "context_integration",
               "context_size": size,
               "processing_time": end_time - start_time
           })
   ```

7. **Backward Compatibility Tests**:
   ```python
   def test_backward_compatibility():
       # Test with old-style configuration
       old_config = {
           "journal": {
               "path": "/tmp/journal"
           }
       }
       
       # Create test commit
       repo = create_test_repo()
       commit_hash = create_test_commit(repo)
       
       # Verify journal generation still works with old config
       entry = generate_journal_entry(commit_hash, old_config)
       assert entry is not None
       assert "commit_hash" in entry
   ```

8. **Manual Testing Checklist**:
   - Verify journal generation with all context sources available
   - Verify fallback behavior when Cursor database is unavailable
   - Verify AI synthesis with different detail levels
   - Verify telemetry records are properly formatted
   - Test with large git diffs to ensure performance
   - Test with rate-limited AI service to verify retry behavior
