# Task ID: 11
# Title: Implement Summary Generation
# Status: pending
# Dependencies: 5, 6, 7, 17, 18
# Priority: medium
# Description: Create the functionality to generate daily, weekly, monthly, and yearly summaries of journal entries.
# Details:
Implement summary generation in the MCP server with the following features:

1. Date range utilities:
```python
def get_date_range(period, date=None):
    """Get start and end dates for a period"""
    if date is None:
        date = datetime.now().date()
    elif isinstance(date, str):
        date = datetime.strptime(date, "%Y-%m-%d").date()
    
    if period == "day":
        return date, date
    elif period == "week":
        # Start of week (Monday)
        start = date - timedelta(days=date.weekday())
        end = start + timedelta(days=6)
        return start, end
    elif period == "month":
        start = date.replace(day=1)
        # Last day of month
        next_month = date.replace(day=28) + timedelta(days=4)
        end = next_month - timedelta(days=next_month.day)
        return start, end
    elif period == "year":
        start = date.replace(month=1, day=1)
        end = date.replace(month=12, day=31)
        return start, end
    else:
        raise ValueError(f"Unknown period: {period}")
```

2. Journal file collection:
```python
def get_journal_files_in_range(start_date, end_date, config):
    """Get journal files in date range"""
    files = []
    current = start_date
    while current <= end_date:
        file_path = Path(config["journal"]["path"]) / "daily" / f"{current.strftime('%Y-%m-%d')}.md"
        if file_path.exists():
            files.append(file_path)
        current += timedelta(days=1)
    return files
```

3. Summary generation:
```python
def generate_summary(files, period, config):
    """Generate summary from journal files"""
    # Extract content from files
    entries = []
    manual_reflections = []
    
    for file_path in files:
        with open(file_path, "r") as f:
            content = f.read()
            # Extract entries and reflections
            # Implementation
    
    # Analyze entries for significance/complexity
    weighted_entries = []
    for entry in entries:
        # Determine entry significance based on factors like:
        # - Length/detail of the entry
        # - Presence of technical terms or complex concepts
        # - Keywords indicating substantial work ("implemented", "designed", "solved")
        # - Absence of trivial indicators ("minor fix", "typo", "small change")
        significance_score = calculate_entry_significance(entry)
        weighted_entries.append((entry, significance_score))
    
    # Sort entries by significance score to prioritize important work
    weighted_entries.sort(key=lambda x: x[1], reverse=True)
    
    # Generate summary sections
    summary = []
    
    # Add manual reflections section if any
    if manual_reflections:
        summary.append("# Manual Reflections\n")
        summary.append("\n".join(manual_reflections))
    
    # Add other sections
    summary.append("# Summary\n")
    # Generate overall summary with emphasis on significant entries
    
    summary.append("# Key Accomplishments\n")
    # Extract accomplishments, prioritizing substantial work
    
    summary.append("# Challenges\n")
    # Extract challenges, focusing on complex problems
    
    summary.append("# Technical Decisions\n")
    # Extract decisions, highlighting important architectural choices
    
    return "\n\n".join(summary)

def calculate_entry_significance(entry):
    """Calculate significance score for an entry to prioritize substantial work"""
    score = 0
    
    # Base score from length (longer entries often indicate more substantial work)
    score += min(len(entry) / 100, 5)  # Cap at 5 points for length
    
    # Keywords indicating substantial work
    substantial_indicators = [
        "implement", "design", "architecture", "refactor", "optimize", 
        "solve", "complex", "challenge", "significant", "major"
    ]
    
    # Keywords indicating trivial work
    trivial_indicators = [
        "typo", "minor fix", "small change", "tweak", "trivial", 
        "cosmetic", "rename", "formatting"
    ]
    
    # Add points for substantial work indicators
    for word in substantial_indicators:
        if word in entry.lower():
            score += 2
    
    # Subtract points for trivial work indicators
    for word in trivial_indicators:
        if word in entry.lower():
            score -= 1.5
    
    # Analyze for technical complexity
    # (This could be enhanced with more sophisticated NLP in the future)
    technical_terms = ["algorithm", "database", "architecture", "performance", "security"]
    for term in technical_terms:
        if term in entry.lower():
            score += 1
    
    return max(score, 0)  # Ensure score doesn't go negative
```

4. Summary file saving:
```python
def save_summary(content, period, date, config):
    """Save summary to appropriate file"""
    if period == "day":
        file_name = f"{date.strftime('%Y-%m-%d')}-summary.md"
        dir_path = Path(config["journal"]["path"]) / "summaries" / "daily"
    elif period == "week":
        # Get week number
        week_num = date.isocalendar()[1]
        file_name = f"{date.strftime('%Y-%m')}-week{week_num}.md"
        dir_path = Path(config["journal"]["path"]) / "summaries" / "weekly"
    elif period == "month":
        file_name = f"{date.strftime('%Y-%m')}.md"
        dir_path = Path(config["journal"]["path"]) / "summaries" / "monthly"
    elif period == "year":
        file_name = f"{date.strftime('%Y')}.md"
        dir_path = Path(config["journal"]["path"]) / "summaries" / "yearly"
    else:
        raise ValueError(f"Unknown period: {period}")
    
    # Create file path
    file_path = dir_path / file_name
    
    # Ensure directory exists using on-demand directory creation pattern
    ensure_journal_directory(dir_path)
    
    # Save file
    with open(file_path, "w") as f:
        f.write(content)
    
    return file_path
```

5. MCP handler implementation:
```python
@trace_operation("journal_summarize")
async def handle_summarize(request):
    """Handle journal/summarize operation"""
    period = request.get("period", "day")
    date = request.get("date")
    date_range = request.get("range")
    
    # Load config
    config = load_config()
    
    # Get date range
    if date_range:
        # Parse range (format: "YYYY-MM-DD:YYYY-MM-DD")
        start_str, end_str = date_range.split(":")
        start_date = datetime.strptime(start_str, "%Y-%m-%d").date()
        end_date = datetime.strptime(end_str, "%Y-%m-%d").date()
    else:
        start_date, end_date = get_date_range(period, date)
    
    # Get journal files
    files = get_journal_files_in_range(start_date, end_date, config)
    if not files:
        return {"status": "error", "error": "No journal entries found in date range"}
    
    # Generate summary
    content = generate_summary(files, period, config)
    
    # Save summary
    file_path = save_summary(content, period, start_date, config)
    
    return {
        "status": "success",
        "file_path": str(file_path),
        "content": content
    }
```

6. Directory creation utility:
```python
def ensure_journal_directory(dir_path):
    """Ensure the journal directory exists, creating it if necessary"""
    if not dir_path.exists():
        dir_path.mkdir(parents=True, exist_ok=True)
        logger.info(f"Created directory: {dir_path}")
    return dir_path
```

7. On-demand directory creation pattern:
- All summary file-writing operations must use the on-demand directory creation pattern
- Directories should only be created when needed, not upfront
- All summary-writing functions (including save_summary) must call ensure_journal_directory(file_path) before writing
- See docs/on-demand-directory-pattern.md for implementation details and test patterns

Note: This implementation focuses solely on MCP/AI agent operations for summary generation. CLI functionality is limited to setup commands (journal-init, install-hook) only. Refer to updated documentation for details.

# Test Strategy:
1. Unit tests for date range utilities
2. Tests for journal file collection
3. Tests for summary generation
4. Tests for summary file saving
5. Tests for MCP handler implementation
6. Tests for handling different periods (day, week, month, year)
7. Tests for handling date ranges
8. Integration tests for full summary generation flow
9. Tests for entry significance calculation
10. Tests to verify that substantial work is properly prioritized in summaries
11. Tests to verify that trivial entries are de-emphasized in summaries
12. Tests with mixed entry types to ensure proper weighting in the final summary
13. Tests for on-demand directory creation:
    - Test that summary directories are created automatically when they don't exist
    - Test that ensure_journal_directory() is called for all summary types (daily, weekly, monthly, yearly)
    - Test that directory creation works with nested paths
    - Test that no errors occur when directories already exist
    - Test that directories are only created when needed, not upfront
    - Verify that all summary-writing functions call ensure_journal_directory() before writing
    - Follow test patterns described in docs/on-demand-directory-pattern.md
14. Tests to verify that summarization is available as an MCP operation
15. Tests to verify that the AI agent can properly interact with the summarization functionality
16. Verify that summary generation works correctly through the MCP interface only (not CLI)
17. Test that the AI agent can request summaries for different time periods and date ranges

# Subtasks:
## 11.1. Implement entry significance calculation [pending]
### Dependencies: None
### Description: Create the algorithm to analyze journal entries and assign significance scores based on content analysis.
### Details:


## 11.2. Modify summary generation to prioritize significant entries [pending]
### Dependencies: None
### Description: Update the summary generation logic to give more narrative weight to entries with higher significance scores.
### Details:


## 11.3. Create test cases for entry significance calculation [pending]
### Dependencies: None
### Description: Develop test cases with various types of entries (substantial, trivial, mixed) to verify proper significance scoring.
### Details:


## 11.4. Test summary prioritization with real-world examples [pending]
### Dependencies: None
### Description: Test the summary generation with a set of real-world journal entries to ensure meaningful work is properly highlighted.
### Details:


## 11.5. Implement ensure_journal_directory utility [pending]
### Dependencies: None
### Description: Create the utility function to ensure journal directories exist, creating them on-demand if necessary.
### Details:


## 11.6. Update save_summary to use ensure_journal_directory [pending]
### Dependencies: None
### Description: Modify the save_summary function to use the ensure_journal_directory utility for all summary types.
### Details:


## 11.7. Add tests for directory creation functionality [pending]
### Dependencies: None
### Description: Create tests to verify that summary directories are created automatically when they don't exist and that the ensure_journal_directory utility works correctly.
### Details:


## 11.8. Implement on-demand directory creation pattern [pending]
### Dependencies: None
### Description: Update all summary file-writing operations to follow the on-demand directory creation pattern as described in docs/on-demand-directory-pattern.md.
### Details:


## 11.9. Add tests for on-demand directory creation [pending]
### Dependencies: None
### Description: Create tests to verify that directories are only created when needed, not upfront, and that all summary-writing functions call ensure_journal_directory() before writing.
### Details:


## 11.10. Review and update all file-writing operations [pending]
### Dependencies: None
### Description: Review all file-writing operations in the codebase to ensure they follow the on-demand directory creation pattern.
### Details:


## 11.11. Verify MCP operation for summarization [pending]
### Dependencies: None
### Description: Ensure that summarization is properly implemented as an MCP operation and accessible to the AI agent.
### Details:


## 11.12. Test AI agent interaction with summarization [pending]
### Dependencies: None
### Description: Create tests to verify that the AI agent can properly request and process summary generation through the MCP server.
### Details:


## 11.13. Ensure summary generation is MCP-only [pending]
### Dependencies: None
### Description: Verify that summary generation functionality is only available through the MCP interface and not through CLI commands.
### Details:


## 11.14. Update documentation to reflect MCP-only approach [pending]
### Dependencies: None
### Description: Update relevant documentation to clarify that summary generation is only available through the MCP/AI agent interface, not through CLI commands.
### Details:


