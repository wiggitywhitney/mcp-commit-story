# Task 36: Cursor Chat Database Integration - Detailed Subtask Plan

## Subtask 36.1: Cursor-chat-browser Analysis and Workspace Detection Research
**Objective**: Conduct deep analysis of cursor-chat-browser repository to understand workspace detection algorithms, message parsing patterns, and cross-platform path handling.

### Research Steps (No TDD - Research Phase):
1. **ANALYZE CURSOR-CHAT-BROWSER REPOSITORY**
   - Clone and study https://github.com/thomas-pedersen/cursor-chat-browser (397+ stars)
   - Extract workspace detection algorithms for all platforms
   - Document message parsing patterns and JSON structure navigation
   - Map cross-platform path handling (Windows/macOS/Linux/WSL2)
   - Study error recovery mechanisms and permission handling
   - Analyze search/filtering patterns for boundary detection insights
   - Test performance characteristics with large chat histories

2. **VALIDATE IMPLEMENTATION CONFIDENCE**
   - Verify compatibility with current Cursor versions
   - Test message extraction completeness (both human AND AI messages)
   - Validate support for our journal generation use cases
   - Confirm complete message access capabilities
   - Verify intelligent boundary detection mechanisms
   - Test cross-platform compatibility patterns
   - Document error handling patterns and performance characteristics

3. **DOCUMENT RESEARCH FINDINGS**
   - Create comprehensive research document with implementation patterns
   - Document workspace detection algorithms for each platform
   - Record message parsing strategies and boundary detection insights
   - Note performance benchmarks and optimization opportunities
   - Document compatibility findings and integration recommendations
   - **MARK COMPLETE**

---

## Subtask 36.2: Remove Current Chat Context Function and Design SQLite Reader
**Objective**: Remove the limited current chat collection function and design the new SQLite-based approach with proper workspace detection.

### TDD Steps:
1. **WRITE TESTS FIRST**
   - Create `tests/unit/test_cursor_chat_integration.py`
   - Test `detect_cursor_workspace()` function for multi-platform path detection
   - Test `validate_workspace_database()` function for database accessibility
   - Test `get_workspace_hash()` function for hash discovery and validation
   - Test cases: successful detection on each platform, missing workspace, permission errors, invalid database
   - **RUN TESTS - VERIFY THEY FAIL**

2. **GET APPROVAL FOR DESIGN CHOICES**
   - **PAUSE FOR MANUAL APPROVAL**: Should we implement graceful fallback to the old chat collection method if Cursor database is inaccessible, or fail completely?
   - **PAUSE FOR MANUAL APPROVAL**: What should be the priority order for workspace detection methods (most recently modified, content search, path correlation)?
   - **PAUSE FOR MANUAL APPROVAL**: How should we handle user configuration overrides for workspace location (environment variable, config file, or both)?

3. **IMPLEMENT FUNCTIONALITY**
   - Remove `collect_ai_chat_context()` function from `src/mcp_commit_story/context_collection.py`
   - Implement `detect_cursor_workspace()` with multi-platform path detection:
     * Windows: %APPDATA%\\Cursor\\User\\workspaceStorage
     * WSL2: /mnt/c/Users/<USERNAME>/AppData/Roaming/Cursor/User/workspaceStorage
     * macOS: ~/Library/Application Support/Cursor/User/workspaceStorage
     * Linux: ~/.config/Cursor/User/workspaceStorage
     * Linux (remote/SSH): ~/.cursor-server/data/User/workspaceStorage
   - Implement `validate_workspace_database()` for database accessibility checking
   - Implement `get_workspace_hash()` for workspace hash discovery and validation
   - Add user configuration fallback mechanisms
   - **RUN TESTS - VERIFY THEY PASS**

4. **DOCUMENT AND COMPLETE**
   - Add documentation IF NEEDED in three places:
     1. **Docs directory**: Update cursor-chat-discovery.md with new workspace detection implementation
     2. **PRD**: Update multi-timeframe summaries section to reflect enhanced chat context capabilities
     3. **Engineering Spec**: Add technical details about workspace detection algorithms and cross-platform support
   - **Do not remove existing information unless it's incorrect**
   - **No approval needed** - make documentation edits directly
   - **Run the entire test suite and make sure all tests are passing**
   - **Make sure pyproject.toml is updated as needed**
   - Double check all subtask requirements are met before marking this subtask as complete
   - **MARK COMPLETE**

---

## Subtask 36.3: Implement Direct Database Query Function
**Objective**: Create a function to query the Cursor chat database and extract complete conversation history with proper parsing and error handling.

### TDD Steps:
1. **WRITE TESTS FIRST**
   - Create `tests/unit/test_cursor_database_query.py`
   - Test `query_cursor_chat_history()` function with mock database responses
   - Test `parse_chat_json()` function for JSON structure parsing
   - Test `extract_message_metadata()` function for timestamp and attribution parsing
   - Test cases: successful query with mixed human/AI messages, empty database, corrupted JSON, missing timestamps, large chat histories
   - **RUN TESTS - VERIFY THEY FAIL**

2. **GET APPROVAL FOR DESIGN CHOICES**
   - **PAUSE FOR MANUAL APPROVAL**: What should be the chat boundary detection strategy - time-based (last N hours), message-based (last N messages), or topic-change detection?
   - **PAUSE FOR MANUAL APPROVAL**: How should we handle message attribution when the JSON format changes between Cursor versions?
   - **PAUSE FOR MANUAL APPROVAL**: Should we implement message caching to avoid re-querying the database for the same timeframe?

3. **IMPLEMENT FUNCTIONALITY**
   - Implement `query_cursor_chat_history()` in `src/mcp_commit_story/context_collection.py`
   - Query `ItemTable` where `key='aiService.prompts'` using Python's built-in sqlite3
   - Implement `parse_chat_json()` to handle the returned JSON format
   - Implement `extract_message_metadata()` for timestamps and conversation context
   - Ensure both human and AI messages are captured with proper attribution
   - Handle message threading and conversation context preservation
   - Add comprehensive error handling and logging
   - **RUN TESTS - VERIFY THEY PASS**

4. **DOCUMENT AND COMPLETE**
   - Add documentation IF NEEDED in three places:
     1. **Docs directory**: Update cursor-chat-discovery.md with database query implementation details
     2. **PRD**: Update context collection capabilities description
     3. **Engineering Spec**: Document the database query architecture and message parsing logic
   - **Do not remove existing information unless it's incorrect**
   - **No approval needed** - make documentation edits directly
   - **Run the entire test suite and make sure all tests are passing**
   - **Make sure pyproject.toml is updated as needed**
   - Double check all subtask requirements are met before marking this subtask as complete
   - **MARK COMPLETE**

---

## Subtask 36.4: Implement Chat Boundary Detection Logic
**Objective**: Create intelligent boundary detection for chat context using complete conversation history access with configurable limits and topic change detection.

### TDD Steps:
1. **WRITE TESTS FIRST**
   - Create `tests/unit/test_chat_boundary_detection.py`
   - Test `detect_conversation_boundaries()` function with various conversation patterns
   - Test `detect_topic_changes()` function for topic shift identification
   - Test `apply_boundary_limits()` function for configurable limits
   - Test cases: single topic conversation, multiple topic shifts, conversation breaks, manual delimiters, very long conversations
   - **RUN TESTS - VERIFY THEY FAIL**

2. **GET APPROVAL FOR DESIGN CHOICES**
   - **PAUSE FOR MANUAL APPROVAL**: Should topic change detection use keyword analysis, semantic similarity, or explicit user markers (or a combination)?
   - **PAUSE FOR MANUAL APPROVAL**: What should be the default boundary limits (time window, message count, or both) and should they be configurable per user?
   - **PAUSE FOR MANUAL APPROVAL**: How should we handle edge cases like very short conversations or conversations with no clear topic boundaries?

3. **IMPLEMENT FUNCTIONALITY**
   - Implement `detect_conversation_boundaries()` with smart boundary detection
   - Implement `detect_topic_changes()` for topic change analysis
   - Implement `apply_boundary_limits()` with configurable limits and intelligent defaults
   - Add support for conversation breaks, topic changes, and manual delimiters
   - Implement topic change detection mechanisms and session separation logic
   - Support both automatic and manual boundary configuration
   - **RUN TESTS - VERIFY THEY PASS**

4. **DOCUMENT AND COMPLETE**
   - Add documentation IF NEEDED in three places:
     1. **Docs directory**: Update cursor-chat-discovery.md with boundary detection algorithms
     2. **PRD**: Update intelligent context collection feature description
     3. **Engineering Spec**: Document boundary detection logic and configuration options
   - **Do not remove existing information unless it's incorrect**
   - **No approval needed** - make documentation edits directly
   - **Run the entire test suite and make sure all tests are passing**
   - **Make sure pyproject.toml is updated as needed**
   - Double check all subtask requirements are met before marking this subtask as complete
   - **MARK COMPLETE**

---

## Subtask 36.5: Update Four-Source Context Integration
**Objective**: Update downstream components to process four distinct context sources (git, terminal, cursor chat database, synthesized summary) with proper fallback handling.

### TDD Steps:
1. **WRITE TESTS FIRST**
   - Create `tests/unit/test_four_source_context_integration.py`
   - Test `collect_all_context_sources()` function with all four sources available
   - Test `handle_missing_context_sources()` function for graceful degradation
   - Test `maintain_backward_compatibility()` function for existing journal generation
   - Test cases: all sources available, one source missing, multiple sources missing, all sources unavailable
   - **RUN TESTS - VERIFY THEY FAIL**

2. **GET APPROVAL FOR DESIGN CHOICES**
   - **PAUSE FOR MANUAL APPROVAL**: How should we prioritize context sources when multiple sources provide conflicting information?
   - **PAUSE FOR MANUAL APPROVAL**: Should we modify the existing journal generation functions or create new ones for four-source context?
   - **PAUSE FOR MANUAL APPROVAL**: What should be the fallback behavior when Cursor chat database is unavailable - use old chat collection, skip chat entirely, or fail generation?

3. **IMPLEMENT FUNCTIONALITY**
   - Update `generate_journal_entry` functions in `src/mcp_commit_story/journal_orchestrator.py`
   - Implement `collect_all_context_sources()` to gather git, terminal, chat, and summary context
   - Implement `handle_missing_context_sources()` for graceful degradation
   - Ensure backward compatibility with existing journal generation workflows
   - Handle cases where some context sources might be unavailable
   - Update context passing to AI generation functions
   - **RUN TESTS - VERIFY THEY PASS**

4. **DOCUMENT AND COMPLETE**
   - Add documentation IF NEEDED in three places:
     1. **Docs directory**: Update summary-generation.md with four-source context capabilities
     2. **PRD**: Update journal generation feature description with enhanced context
     3. **Engineering Spec**: Document four-source context architecture and integration patterns
   - **Do not remove existing information unless it's incorrect**
   - **No approval needed** - make documentation edits directly
   - **Run the entire test suite and make sure all tests are passing**
   - **Make sure pyproject.toml is updated as needed**
   - Double check all subtask requirements are met before marking this subtask as complete
   - **MARK COMPLETE**

---

## Subtask 36.6: Implement Synthesized Summary Collection
**Objective**: Create a new synthesized summary collection function that uses AI prompts to generate high-level summaries of conversations with configurable options.

### TDD Steps:
1. **WRITE TESTS FIRST**
   - Create `tests/unit/test_synthesized_summary_collection.py`
   - Test `generate_conversation_summary()` function with various conversation types
   - Test `configure_summary_options()` function for detail level and focus areas
   - Test `handle_rate_limiting()` function for API error handling
   - Test cases: technical discussions, design decisions, troubleshooting sessions, rate limit errors, API failures
   - **RUN TESTS - VERIFY THEY FAIL**

2. **GET APPROVAL FOR DESIGN CHOICES**
   - **PAUSE FOR MANUAL APPROVAL**: What AI model should we use for summary generation and should it be configurable?
   - **PAUSE FOR MANUAL APPROVAL**: How should we structure the summary prompt to focus on journal-relevant information?
   - **PAUSE FOR MANUAL APPROVAL**: What configuration options should we provide (summary length, technical detail level, focus areas)?

3. **IMPLEMENT FUNCTIONALITY**
   - Implement `generate_conversation_summary()` in `src/mcp_commit_story/context_collection.py`
   - Create AI prompts for high-level conversation summarization
   - Implement `configure_summary_options()` for detail level and focus area configuration
   - Implement `handle_rate_limiting()` with graceful API error handling
   - Add telemetry for summary generation operations
   - **RUN TESTS - VERIFY THEY PASS**

4. **DOCUMENT AND COMPLETE**
   - Add documentation IF NEEDED in three places:
     1. **Docs directory**: Update summary-generation.md with synthesized summary capabilities
     2. **PRD**: Add synthesized summary collection as a new feature
     3. **Engineering Spec**: Document AI summary generation architecture and configuration
   - **Do not remove existing information unless it's incorrect**
   - **No approval needed** - make documentation edits directly
   - **Run the entire test suite and make sure all tests are passing**
   - **Make sure pyproject.toml is updated as needed**
   - Double check all subtask requirements are met before marking this subtask as complete
   - **MARK COMPLETE**

---

## Subtask 36.7: Add Performance Caching Mechanisms
**Objective**: Implement caching mechanisms to avoid regenerating summaries unnecessarily and optimize database query performance with configuration caching.

### TDD Steps:
1. **WRITE TESTS FIRST**
   - Create `tests/unit/test_performance_caching.py`
   - Test `cache_conversation_summaries()` function for summary caching
   - Test `cache_database_queries()` function for query result caching
   - Test `cache_configuration()` function for configuration caching
   - Test cases: cache hits, cache misses, cache invalidation, memory usage, cache size limits
   - **RUN TESTS - VERIFY THEY FAIL**

2. **IMPLEMENT FUNCTIONALITY**
   - Implement `cache_conversation_summaries()` to avoid regenerating summaries
   - Implement `cache_database_queries()` to optimize database query performance
   - Implement `cache_configuration()` for performance optimization
   - Add cache invalidation logic for data freshness
   - Add memory usage monitoring and cache size limits
   - **RUN TESTS - VERIFY THEY PASS**

3. **DOCUMENT AND COMPLETE**
   - Add documentation IF NEEDED in three places:
     1. **Docs directory**: Update cursor-chat-discovery.md with caching implementation details
     2. **PRD**: Update performance characteristics description
     3. **Engineering Spec**: Document caching architecture and configuration options
   - **Do not remove existing information unless it's incorrect**
   - **No approval needed** - make documentation edits directly
   - **Run the entire test suite and make sure all tests are passing**
   - **Make sure pyproject.toml is updated as needed**
   - Double check all subtask requirements are met before marking this subtask as complete
   - **MARK COMPLETE**

---

## Subtask 36.8: Implement Cross-Platform Support and Error Handling
**Objective**: Leverage cursor-chat-browser patterns for cross-platform compatibility and implement robust error handling with clear user-facing diagnostics.

### TDD Steps:
1. **WRITE TESTS FIRST**
   - Create `tests/integration/test_cross_platform_support.py`
   - Test platform detection on Windows, macOS, Linux, and WSL2 (use mocks)
   - Test permission handling with various access scenarios
   - Test error recovery mechanisms for corrupted/missing databases
   - Test user-friendly diagnostic messages
   - Test cases: each platform type, permission denied, corrupted database, missing workspace, network drive locations
   - **RUN TESTS - VERIFY THEY FAIL**

2. **GET APPROVAL FOR DESIGN CHOICES**
   - **PAUSE FOR MANUAL APPROVAL**: Should we auto-detect the platform or allow manual platform specification in configuration?
   - **PAUSE FOR MANUAL APPROVAL**: What level of diagnostic information should we provide to users (detailed technical info vs simplified messages)?
   - **PAUSE FOR MANUAL APPROVAL**: How should we handle edge cases like network-mounted Cursor installations or non-standard installation paths?

3. **IMPLEMENT FUNCTIONALITY**
   - Implement cross-platform path handling using cursor-chat-browser patterns
   - Add permission handling with clear error messages for database access issues
   - Create repeatable setup for any end user's environment with auto-detection
   - Implement robust error recovery mechanisms for corrupted/missing databases
   - Add user-friendly diagnostics that check workspace accessibility and chat data availability
   - Provide helpful error messages and troubleshooting guidance
   - **RUN TESTS - VERIFY THEY PASS**

4. **DOCUMENT AND COMPLETE**
   - Add documentation IF NEEDED in three places:
     1. **Docs directory**: Create cross-platform-setup.md with installation guidance for each platform
     2. **PRD**: Update system requirements and compatibility information
     3. **Engineering Spec**: Document cross-platform architecture and error handling patterns
   - **Do not remove existing information unless it's incorrect**
   - **No approval needed** - make documentation edits directly
   - **Run the entire test suite and make sure all tests are passing**
   - **Make sure pyproject.toml is updated as needed**
   - Double check all subtask requirements are met before marking this subtask as complete
   - **MARK COMPLETE**

---

## Subtask 36.9: Add Comprehensive Telemetry and Final Documentation
**Objective**: Implement comprehensive telemetry as defined in docs/telemetry.md and create final documentation for the complete Cursor chat database integration system.

### TDD Steps:
1. **WRITE TESTS FIRST**
   - Create `tests/unit/test_cursor_chat_telemetry.py`
   - Test telemetry events for workspace detection, database queries, and error conditions
   - Test telemetry data format and collection patterns
   - Test privacy considerations for chat data in telemetry
   - Test cases: successful operations, error conditions, performance metrics, data privacy compliance
   - **RUN TESTS - VERIFY THEY FAIL**

2. **GET APPROVAL FOR DESIGN CHOICES**
   - **PAUSE FOR MANUAL APPROVAL**: What telemetry data should we collect for chat operations (performance only, or include anonymized usage patterns)?
   - **PAUSE FOR MANUAL APPROVAL**: How should we handle telemetry when processing sensitive chat data (anonymization, opt-out, etc.)?

3. **IMPLEMENT FUNCTIONALITY**
   - Add comprehensive telemetry following patterns in `docs/telemetry.md`
   - Implement telemetry for workspace detection, database queries, and summary generation
   - Add performance metrics and error condition tracking
   - Ensure privacy compliance for chat data telemetry
   - Update all new functions with appropriate telemetry decorators
   - **RUN TESTS - VERIFY THEY PASS**

4. **DOCUMENT AND COMPLETE**
   - Add documentation IF NEEDED in three places:
     1. **Docs directory**: Create comprehensive cursor-chat-integration.md user guide
     2. **PRD**: Mark Cursor chat database integration as completed feature with full capabilities
     3. **Engineering Spec**: Complete technical documentation with architecture diagrams and implementation details, update TOC
   - **Do not remove existing information unless it's incorrect**
   - **No approval needed** - make documentation edits directly
   - **Run the entire test suite and make sure all tests are passing**
   - **Make sure pyproject.toml is updated as needed**
   - Double check all subtask requirements are met before marking this subtask as complete
   - **MARK COMPLETE**

---

## Implementation Notes

### Key Success Criteria
- Zero external dependencies (uses built-in sqlite3)
- Cross-platform compatibility (Windows/macOS/Linux/WSL2)
- Graceful fallback when Cursor database unavailable
- Complete message extraction (human + AI)
- Intelligent boundary detection with configurable limits
- Performance optimization through caching
- Comprehensive error handling and user diagnostics

### Testing Strategy Overview
- **Unit tests** for all individual functions with mock dependencies
- **Integration tests** for cross-platform compatibility and real database access
- **Performance tests** for large chat history handling and caching effectiveness
- **Error condition tests** for all failure scenarios and recovery mechanisms

### Documentation Strategy
- **User-facing docs** for installation and troubleshooting
- **PRD updates** for feature completeness and capabilities
- **Technical specs** for architecture and implementation details
- **Telemetry documentation** following established patterns 