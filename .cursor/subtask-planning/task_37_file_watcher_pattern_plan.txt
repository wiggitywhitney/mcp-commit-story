# Task 37: Implement File Watcher Pattern for MCP Tool Signaling in Git Hook Worker - Detailed Subtask Plan

## Subtask 37.1: Create MCP Server Entry Point with Comprehensive Telemetry
**Objective**: Implement properly instrumented `src/mcp_commit_story/__main__.py` as the official entry point for `python -m mcp_commit_story` command used in `.cursor/mcp.json` configuration.

### TDD Steps:
1. **WRITE TESTS FIRST**
   - Create `tests/unit/test_mcp_server_entry_point.py`
   - Test `main()` function with successful server startup and shutdown
   - Test `validate_server_config()` function for configuration validation
   - Test `setup_server_telemetry()` function for telemetry initialization
   - Test cases: successful startup with valid config, startup failure with invalid config, graceful shutdown on interrupt, error handling with detailed logging, telemetry recording for all server lifecycle events
   - **RUN TESTS - VERIFY THEY FAIL**

2. **GET APPROVAL FOR DESIGN CHOICES**
   - **PAUSE FOR MANUAL APPROVAL**: Should the entry point use the existing `create_mcp_server()` function or implement its own server initialization for better control?
   - **PAUSE FOR MANUAL APPROVAL**: What should be the exit code strategy (standard codes vs custom codes) and how should we handle different error scenarios?
   - **PAUSE FOR MANUAL APPROVAL**: Should telemetry setup failure be fatal or should the server continue with degraded observability?

3. **IMPLEMENT FUNCTIONALITY**
   - Implement `src/mcp_commit_story/__main__.py` with proper imports and error handling
   - Implement `main()` function using existing `create_mcp_server()` and stdio transport
   - Implement comprehensive telemetry recording using existing `get_mcp_metrics()` patterns:
     * `server_start_attempt`, `server_started`, `server_shutdown`
     * `server_startup_error`, `server_keyboard_interrupt`
     * Duration tracking for server lifecycle events
   - Add proper logging configuration and structured error messages
   - Ensure graceful handling of KeyboardInterrupt and unexpected exceptions
   - Follow established project patterns for configuration loading and validation
   - **RUN TESTS - VERIFY THEY PASS**

4. **DOCUMENT AND COMPLETE**
   - Add documentation IF NEEDED in three places:
     1. **Docs directory**: Update server_setup.md with proper entry point usage and troubleshooting
     2. **PRD**: Update MCP server deployment section to reflect standardized entry point
     3. **Engineering Spec**: Update MCP server architecture details and add entry point implementation notes, make sure TOC is current
   - **Do not remove existing information unless it's incorrect**
   - **No approval needed** - make documentation edits directly
   - **Run the entire test suite and make sure all tests are passing**
   - **Make sure pyproject.toml is updated as needed**
   - Double check all subtask requirements are met before marking this subtask as complete
   - **MARK COMPLETE**

---

## Subtask 37.2: Implement Signal Directory Management and File Creation
**Objective**: Create the signal directory structure and implement file-based signaling mechanism for AI client discovery with comprehensive error handling.

### TDD Steps:
1. **WRITE TESTS FIRST**
   - Create `tests/unit/test_signal_file_management.py`
   - Test `ensure_signal_directory()` function for directory creation and validation
   - Test `create_signal_file()` function for generic signal file generation
   - Test `validate_signal_format()` function for JSON structure validation
   - Test cases: successful directory creation, permission errors with graceful degradation, signal file creation with proper metadata, invalid JSON handling, disk space errors, generic tool signal format validation
   - **RUN TESTS - VERIFY THEY FAIL**

2. **GET APPROVAL FOR DESIGN CHOICES**
   - **PAUSE FOR MANUAL APPROVAL**: Should signal files include repository-specific metadata (branch, remote URL) or just commit-specific data?
   - **PAUSE FOR MANUAL APPROVAL**: What should be the signal file naming convention (timestamp + commit hash vs UUID vs sequential) for optimal AI discovery?
   - **PAUSE FOR MANUAL APPROVAL**: Should we implement signal file compression for large commit metadata or keep them as readable JSON?

3. **IMPLEMENT FUNCTIONALITY**
   - Implement `ensure_signal_directory()` in `src/mcp_commit_story/git_hook_worker.py`
     * Create `.mcp-commit-story/signals/` directory with proper permissions
     * Handle permission errors gracefully without blocking git operations
   - Implement `create_signal_file()` with unique timestamped naming:
     * Format: `{timestamp}_{commit_hash[:8]}.json`
     * Include commit metadata: hash, author, message, timestamp, changed files
     * Include tool request: tool name, parameters, priority
   - Implement comprehensive telemetry using `get_mcp_metrics()`:
     * `mcp.signals.directory_created`, `mcp.signals.file_created`
     * `mcp.signals.creation_error`, `mcp.signals.permission_error`
     * File size tracking and creation duration metrics
   - Add structured logging for all signal operations
   - **RUN TESTS - VERIFY THEY PASS**

4. **DOCUMENT AND COMPLETE**
   - Add documentation IF NEEDED in three places:
     1. **Docs directory**: Create signal-file-format.md with JSON schema and AI client integration guide
     2. **PRD**: Update automated journal generation section to reflect file-based signaling approach
     3. **Engineering Spec**: Add signal file architecture details and directory structure documentation, make sure TOC is current
   - **Do not remove existing information unless it's incorrect**
   - **No approval needed** - make documentation edits directly
   - **Run the entire test suite and make sure all tests are passing**
   - **Make sure pyproject.toml is updated as needed**
   - Double check all subtask requirements are met before marking this subtask as complete
   - **MARK COMPLETE**

---

## Subtask 37.3: Replace call_mcp_tool Placeholder with Signal File Creation
**Objective**: Replace the placeholder `call_mcp_tool()` function with generic signal file creation logic while maintaining all existing behavior and comprehensive telemetry.

### TDD Steps:
1. **WRITE TESTS FIRST**
   - Create `tests/unit/test_signal_file_replacement.py`
   - Test `create_tool_signal()` function for generic MCP tool signal creation
   - Test `signal_creation_telemetry()` function for metrics recording
   - Test cases: successful signal creation for all tool types (journal_new_entry, generate_daily_summary, generate_weekly_summary), error handling with graceful degradation, telemetry recording for success and failure cases, signal content validation, parameter validation
   - **RUN TESTS - VERIFY THEY FAIL**

2. **GET APPROVAL FOR DESIGN CHOICES**
   - **PAUSE FOR MANUAL APPROVAL**: Should we maintain the exact same function signature as `call_mcp_tool()` for drop-in replacement or slightly modify for better signal metadata inclusion?
   - **PAUSE FOR MANUAL APPROVAL**: How should we handle the transition period - should the old function remain as a fallback or be completely removed?
   - **PAUSE FOR MANUAL APPROVAL**: Should signal files include additional context like terminal output or chat history hints for AI clients?

3. **IMPLEMENT FUNCTIONALITY**
   - Replace `call_mcp_tool()` function with generic signal file creation implementation
   - Implement `create_tool_signal(tool_name: str, parameters: Dict[str, Any], commit_metadata: Dict[str, Any], repo_path: str)`:
     * Generic signal format: `{"tool": tool_name, "params": parameters, "metadata": commit_metadata, "created_at": timestamp}`
     * Works for any MCP tool: "journal_new_entry", "generate_daily_summary", "generate_weekly_summary", etc.
     * Single implementation reduces duplication and maintenance overhead
   - Maintain all existing function call patterns in main git hook workflow
   - Add comprehensive telemetry for signal creation success/failure rates
   - Ensure graceful degradation - never block git operations even if signal creation fails
   - Include commit metadata extraction using existing git utilities
   - **RUN TESTS - VERIFY THEY PASS**

4. **DOCUMENT AND COMPLETE**
   - Add documentation IF NEEDED in three places:
     1. **Docs directory**: Update git-hook-integration.md with signal file creation behavior
     2. **PRD**: Update git hook workflow section to reflect file-based signaling mechanism
     3. **Engineering Spec**: Update git hook worker architecture and signal creation flow, make sure TOC is current
   - **Do not remove existing information unless it's incorrect**
   - **No approval needed** - make documentation edits directly
   - **Run the entire test suite and make sure all tests are passing**
   - **Make sure pyproject.toml is updated as needed**
   - Double check all subtask requirements are met before marking this subtask as complete
   - **MARK COMPLETE**

---

## Subtask 37.4: Implement Signal File Cleanup and Maintenance
**Objective**: Create automated cleanup mechanisms for signal files to prevent directory growth and implement maintenance utilities with proper telemetry.

### TDD Steps:
1. **WRITE TESTS FIRST**
   - Create `tests/unit/test_signal_file_cleanup.py`
   - Test `cleanup_old_signals()` function for age-based cleanup
   - Test `cleanup_processed_signals()` function for processed file removal
   - Test `validate_cleanup_safety()` function for safe cleanup operations
   - Test cases: successful cleanup of old files, handling of active/locked files, permission errors during cleanup, cleanup telemetry recording, preservation of recent signals
   - **RUN TESTS - VERIFY THEY FAIL**

2. **GET APPROVAL FOR DESIGN CHOICES**
   - **PAUSE FOR MANUAL APPROVAL**: What should be the default signal file retention period (24 hours, 7 days, or configurable) and should it be user-configurable?
   - **PAUSE FOR MANUAL APPROVAL**: Should we implement a processed signal marker (file rename, separate directory, or metadata flag) to avoid re-processing?
   - **PAUSE FOR MANUAL APPROVAL**: Should cleanup run automatically on each git hook execution or be a separate scheduled operation?

3. **IMPLEMENT FUNCTIONALITY**
   - Implement `cleanup_old_signals()` with configurable age-based cleanup:
     * Default: Remove signals older than 24 hours
     * Configurable via environment variable or config file
   - Implement `cleanup_processed_signals()` for removing processed signals:
     * Check for lock files or processing markers
     * Safe removal without disrupting active AI processing
   - Add cleanup integration to main git hook workflow:
     * Run cleanup before creating new signals
     * Limit cleanup execution frequency to avoid performance impact
   - Implement comprehensive telemetry:
     * `mcp.signals.cleanup_executed`, `mcp.signals.files_removed`
     * `mcp.signals.cleanup_error`, `mcp.signals.cleanup_duration`
   - Add error handling for permission issues and disk space problems
   - **RUN TESTS - VERIFY THEY PASS**

4. **DOCUMENT AND COMPLETE**
   - Add documentation IF NEEDED in three places:
     1. **Docs directory**: Update signal-file-format.md with cleanup mechanisms and configuration options
     2. **PRD**: Update system maintenance section to reflect automated cleanup capabilities
     3. **Engineering Spec**: Add signal file lifecycle management details and cleanup architecture, make sure TOC is current
   - **Do not remove existing information unless it's incorrect**
   - **No approval needed** - make documentation edits directly
   - **Run the entire test suite and make sure all tests are passing**
   - **Make sure pyproject.toml is updated as needed**
   - Double check all subtask requirements are met before marking this subtask as complete
   - **MARK COMPLETE**

---

## Subtask 37.5: Implement Enhanced Commit Metadata Extraction
**Objective**: Create comprehensive commit metadata extraction for signal files using existing git utilities with proper error handling and telemetry.

### TDD Steps:
1. **WRITE TESTS FIRST**
   - Create `tests/unit/test_commit_metadata_extraction.py`
   - Test `extract_commit_metadata()` function for comprehensive commit information
   - Test `get_commit_file_changes()` function for file change analysis
   - Test `calculate_commit_impact()` function for impact assessment
   - Test cases: normal commits with file changes, merge commits, initial commits, commits with binary files, large commits with many files
   - **RUN TESTS - VERIFY THEY FAIL**

2. **GET APPROVAL FOR DESIGN CHOICES**
   - **PAUSE FOR MANUAL APPROVAL**: Should commit metadata include diff content or just file change summaries to balance signal file size vs information richness?
   - **PAUSE FOR MANUAL APPROVAL**: How should we handle large commits (100+ files) - should we truncate file lists or use statistical summaries?
   - **PAUSE FOR MANUAL APPROVAL**: Should we include branch information and remote repository context in signal metadata?

3. **IMPLEMENT FUNCTIONALITY**
   - Implement `extract_commit_metadata()` using existing git utilities:
     * Leverage `get_commit_details()` from `git_utils.py`
     * Extract author, timestamp, message, hash, and change statistics
   - Implement `get_commit_file_changes()` for detailed file analysis:
     * File types, change counts, additions/deletions
     * Directory impact analysis and file categorization
   - Implement `calculate_commit_impact()` for impact assessment:
     * Change magnitude, file diversity, code complexity hints
   - Add comprehensive error handling for git operations:
     * Handle missing commits, corrupted repositories, permission issues
   - Implement telemetry for metadata extraction:
     * `mcp.signals.metadata_extracted`, `mcp.signals.extraction_error`
     * Duration tracking and metadata size metrics
   - **RUN TESTS - VERIFY THEY PASS**

4. **DOCUMENT AND COMPLETE**
   - Add documentation IF NEEDED in three places:
     1. **Docs directory**: Update signal-file-format.md with metadata schema and extraction details
     2. **PRD**: Update commit analysis capabilities section with enhanced metadata extraction
     3. **Engineering Spec**: Add commit metadata extraction architecture and git utilities integration, make sure TOC is current
   - **Do not remove existing information unless it's incorrect**
   - **No approval needed** - make documentation edits directly
   - **Run the entire test suite and make sure all tests are passing**
   - **Make sure pyproject.toml is updated as needed**
   - Double check all subtask requirements are met before marking this subtask as complete
   - **MARK COMPLETE**

---

## Subtask 37.6: Integration Testing and End-to-End Validation
**Objective**: Create comprehensive integration tests for the complete file watcher pattern workflow and validate end-to-end functionality with real git operations.

### TDD Steps:
1. **WRITE TESTS FIRST**
   - Create `tests/integration/test_file_watcher_end_to_end.py`
   - Test `test_complete_git_hook_workflow()` function for full workflow validation
   - Test `test_signal_discovery_simulation()` function for AI client simulation
   - Test `test_error_recovery_scenarios()` function for error handling validation
   - Test cases: complete git commit to signal creation workflow, multiple concurrent commits, signal file discovery and processing simulation, error scenarios with graceful degradation, performance under load
   - **RUN TESTS - VERIFY THEY FAIL**

2. **GET APPROVAL FOR DESIGN CHOICES**
   - **PAUSE FOR MANUAL APPROVAL**: Should integration tests include actual AI client simulation or just validate signal file format and availability?
   - **PAUSE FOR MANUAL APPROVAL**: How should we test the MCP server entry point - with actual stdio communication or mock transport?
   - **PAUSE FOR MANUAL APPROVAL**: Should we include performance benchmarks in the test suite or keep them as separate validation?

3. **IMPLEMENT FUNCTIONALITY**
   - Implement complete end-to-end integration test:
     * Create test git repository with realistic commit scenarios
     * Execute git hook workflow and validate signal file creation
     * Simulate AI client discovery and processing
   - Implement error recovery scenario testing:
     * Test permission errors, disk space issues, corrupted git state
     * Validate graceful degradation and error telemetry
   - Implement performance validation:
     * Measure signal creation time and file system impact
     * Validate git hook execution doesn't slow down git operations
   - Add comprehensive telemetry validation:
     * Verify all expected metrics are recorded
     * Test telemetry data accuracy and completeness
   - Test MCP server entry point with realistic scenarios:
     * Startup, signal processing, shutdown sequences
     * Error handling and recovery testing
   - **RUN TESTS - VERIFY THEY PASS**

4. **DOCUMENT AND COMPLETE**
   - Add documentation IF NEEDED in three places:
     1. **Docs directory**: Create file-watcher-integration.md with complete setup and troubleshooting guide
     2. **PRD**: Update automated journal generation workflow with file watcher pattern details
     3. **Engineering Spec**: Add integration testing architecture and end-to-end workflow documentation, make sure TOC is current
   - **Do not remove existing information unless it's incorrect**
   - **No approval needed** - make documentation edits directly
   - **Run the entire test suite and make sure all tests are passing**
   - **Make sure pyproject.toml is updated as needed**
   - Double check all subtask requirements are met before marking this subtask as complete
   - **MARK COMPLETE** 